{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h9DEdocHXqz7"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5O7UKAl_XyWT"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VaeHFswdX_RT"
   },
   "outputs": [],
   "source": [
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qglozo93Xgu_"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import error, spaces, utils\n",
    "from gym.utils import seeding\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "class FraudEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        self.f = 'dataset/creditcard.csv'\n",
    "        self.df_xy = pd.DataFrame(pd.read_csv(self.f))\n",
    "        self.ACTION_LOOKUP = {0: 'not_fraud', 1: 'fraud'}\n",
    "\n",
    "        self.action_space = spaces.Discrete(len(self.ACTION_LOOKUP))\n",
    "        self.observation_space = spaces.Discrete(self.df_xy.shape[0])\n",
    "\n",
    "        self.ob = self._get_random_initial_state()\n",
    "        self.episode_over = False\n",
    "        self.turns = 0\n",
    "        self.sum_rewards = 0.0\n",
    "        self.action = 0.0\n",
    "        self.current_state_index = 0\n",
    "        \n",
    "\n",
    "    def step(self, predicted_action_index):\n",
    "        \"\"\"\n",
    "                Parameters\n",
    "                ----------\n",
    "                action_index :\n",
    "                Returns\n",
    "                -------\n",
    "                ob, reward, episode_over, info : tuple\n",
    "                    ob (object) :\n",
    "                        an environment-specific object representing your observation of\n",
    "                        the environment.\n",
    "                    reward (float) :\n",
    "                        amount of reward achieved by the previous action. The scale\n",
    "                        varies between environments, but the goal is always to increase\n",
    "                        your total reward.\n",
    "                    episode_over (bool) :\n",
    "                        whether it's time to reset the environment again. Most (but not\n",
    "                        all) tasks are divided up into well-defined episodes, and done\n",
    "                        being True indicates the episode has terminated. (For example,\n",
    "                        perhaps the pole tipped too far, or you lost your last life.)\n",
    "                    info (dict) :\n",
    "                         diagnostic information useful for debugging. It can sometimes\n",
    "                         be useful for learning (for exam   ple, it might contain the raw\n",
    "                         probabilities behind the environment's last state change).\n",
    "                         However, official evaluations of your agent are not allowed to\n",
    "                         use this for learning.\n",
    "                \"\"\"\n",
    "\n",
    "        self.turns += 1\n",
    "        self.predicted_action = self._take_action(predicted_action_index)\n",
    "        self.reward = self._get_reward(predicted_action_index)\n",
    "        self.ob = self._get_next_state()\n",
    "        if self.turns > 500 or self.sum_rewards > 0:\n",
    "            self.episode_over = True\n",
    "\n",
    "        return self.ob, self.reward, self.episode_over, {}\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "               Reset the environment and supply a new state for initial state\n",
    "               :return:\n",
    "               \"\"\"\n",
    "\n",
    "        self.turns = 0\n",
    "        self.ob = self._get_random_initial_state()\n",
    "        self.episode_over = False\n",
    "        self.sum_rewards = 0.0\n",
    "        return self.ob\n",
    "\n",
    "    def render(self, mode='human', close=False):\n",
    "        pass\n",
    "\n",
    "    def _take_action(self, action_index):\n",
    "        \"\"\"\n",
    "                Take an action correpsonding to action_index in the current state\n",
    "                :param action_index:\n",
    "                :return:\n",
    "                \"\"\"\n",
    "        assert action_index < len(self.ACTION_LOOKUP)\n",
    "        self.action = action_index\n",
    "        return self.action\n",
    "            def take_action(self, action):\n",
    "        if isinstance(action, int):\n",
    "            _, reward, self.done, _ = self.env.step(action) #.item pulls value out of tensor\n",
    "        else:\n",
    "            _, reward, self.done, _ = self.env.step(action.item()) #.item pulls value out of tensor\n",
    "        return torch.tensor([reward], device=self.device) #wrapped in a tensor for pytorch\n",
    "\n",
    "    def _get_random_initial_state(self):\n",
    "        \n",
    "        nrand = random.randint(0, self.df_xy.shape[0]-64)\n",
    "        assert nrand <  self.df_xy.shape[0]\n",
    "        self.current_state_index = nrand\n",
    "        return self.df_xy.iloc[nrand][0:30]\n",
    "\n",
    "    def _get_reward(self, predicted_action):\n",
    "        \"\"\"\n",
    "                Get reward for the action taken in the current state\n",
    "                :return:\n",
    "                \"\"\"\n",
    "        df = self.df_xy\n",
    "        labelled_action = df.iloc[self.current_state_index]['Class']\n",
    "        reward = 0.0\n",
    "        if labelled_action == 0.0:\n",
    "            if predicted_action == 0.0:\n",
    "                reward = 0.001\n",
    "            else:\n",
    "                reward = -0.001\n",
    "        elif labelled_action == 1.0:\n",
    "            if predicted_action == 1.0:\n",
    "                reward = 1.0\n",
    "            else:\n",
    "                reward = -1.0\n",
    "        self.sum_rewards += reward\n",
    "        return reward\n",
    "\n",
    "    def _get_next_state(self):\n",
    "        \"\"\"\n",
    "        Get the next state from current state\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        df = self.df_xy\n",
    "        new_state_index = self.current_state_index + 1\n",
    "        next_state = df.iloc[new_state_index][0:30]\n",
    "        self.current_state_index = new_state_index\n",
    "        return next_state\n",
    "\n",
    "    def _seed(self):\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = FraudEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 651
    },
    "colab_type": "code",
    "id": "iGQr-BeMYA7M",
    "outputId": "7fe2e2c4-ce84-4e3f-ca8f-9a9536266c10",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time      52322.000000\n",
      "V1            1.186044\n",
      "V2            0.185265\n",
      "V3            0.106104\n",
      "V4            1.085587\n",
      "V5            0.329644\n",
      "V6            0.401886\n",
      "V7            0.069674\n",
      "V8            0.014206\n",
      "V9            0.157741\n",
      "V10          -0.130416\n",
      "V11          -1.147540\n",
      "V12           0.602716\n",
      "V13           1.000121\n",
      "V14          -0.090949\n",
      "V15           0.413317\n",
      "V16          -0.146935\n",
      "V17          -0.354708\n",
      "V18          -0.686984\n",
      "V19          -0.110523\n",
      "V20          -0.039051\n",
      "V21          -0.223429\n",
      "V22          -0.504596\n",
      "V23          -0.111696\n",
      "V24          -0.957372\n",
      "V25           0.610404\n",
      "V26          -0.409395\n",
      "V27           0.043860\n",
      "V28           0.018531\n",
      "Amount       33.310000\n",
      "Name: 67002, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "actions = []\n",
    "rewards = []\n",
    "count = 5\n",
    "obs = env.reset()\n",
    "print(obs)\n",
    "while True:\n",
    "  action = env.action_space.sample()\n",
    "  reward = env.step(action)\n",
    "  actions.append(action)\n",
    "  rewards.append(reward)\n",
    "  count -= 1\n",
    "  if count==0:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R5e491gAYDNk"
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.utils.data as data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/creditcard.csv')\n",
    "df.head(1) # give us a sneek preview of the dataset xD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a6ZtDL1xYLgU"
   },
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1].values \n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mo8o0l-iYQGV"
   },
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(30, 16)\n",
    "        self.fc2 = nn.Linear(16, 18)\n",
    "        self.fc3 = nn.Linear(18, 20)\n",
    "        self.fc4 = nn.Linear(20, 24)\n",
    "        self.fc5 = nn.Linear(24, 2)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, p=0.25)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = torch.sigmoid(self.fc5(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G66ErXfxYTzN"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = int(1e5)  #replay buffer size\n",
    "BATCH_SIZE = 64         # minibatch size\n",
    "GAMMA = 0.99            # discount factor\n",
    "TAU = 1e-3              # for soft update of target parameters\n",
    "LR = 5e-4               # learning rate\n",
    "UPDATE_EVERY = 4        # how often to update the network\n",
    "EPSILON = 0.8           # probability of chosing on-policy action\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEEP LIZARD CODE BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory():\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.push_count = 0\n",
    "        \n",
    "    def push(self, experience):\n",
    "        # if memory is not full already\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(experience)\n",
    "        else: \n",
    "            self.memory[self.push_count % self.capacity] = experience\n",
    "        self.push_count += 1\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "        \n",
    "    def can_provide_sample(self, batch):\n",
    "        # check if there are enough saved states in memory to provide an adequate sample\n",
    "        return len(self.memory) >= batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpsilonGreedyStrategy():\n",
    "    def __init__(self, start, end, decay):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.decay = decay\n",
    "        \n",
    "    def get_exploration_rate(self, current_step):\n",
    "        return self.end + (self.start - self.end) * math.exp(-1. * current_step * self.decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, strategy, num_actions, device):\n",
    "        self.current_step = 0\n",
    "        self.strategy = strategy\n",
    "        self.num_actions = num_actions\n",
    "        self.device = device\n",
    "        \n",
    "    def select_action(self, state, policy_net):\n",
    "        rate = strategy.get_exploration_rate(self.current_step)\n",
    "        self.current_step += 1\n",
    "        \n",
    "        if rate > random.random():\n",
    "#             print('explore ', random.randrange(self.num_actions))\n",
    "            a = torch.tensor(random.randrange(self.num_actions))\n",
    "            a = torch.reshape(a, (1,))\n",
    "            return a #explore\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "#                 print('exploit ', policy_net(state).argmax(dim=1).item())\n",
    "                a = torch.tensor(policy_net(state).argmax().item())\n",
    "                a = torch.reshape(a, (1,))\n",
    "                return a #exploit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tensors(experiences):\n",
    "    \n",
    "    batch = Experience(*zip(*experiences))\n",
    "    \n",
    "    t1 = torch.cat(batch.state)\n",
    "    t2 = torch.cat(batch.action)\n",
    "    t3 = torch.cat(batch.reward)\n",
    "    t4 = torch.cat(batch.next_state)\n",
    "    \n",
    "    return (t1,t2,t3,t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "batch_size = 64\n",
    "gamma = 0.999\n",
    "eps_start = 1\n",
    "eps_end = 0.01\n",
    "eps_decay = 0.001\n",
    "target_update = 10\n",
    "memory_size = 100000\n",
    "lr = 0.001\n",
    "num_episodes = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = EpsilonGreedyStrategy(eps_start, eps_end, eps_decay)\n",
    "agent = Agent(strategy, len(env.ACTION_LOOKUP), device)\n",
    "memory = ReplayMemory(memory_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_net = DQN().double().to(device)\n",
    "target_net = DQN().double().to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict()) #imports policy net weights\n",
    "target_net.eval() #not in training mode\n",
    "optimizer = optim.Adam(params=policy_net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython: from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(values, moving_avg_period):\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    plt.title('training...')\n",
    "    plt.xlabel('episode')\n",
    "    plt.ylabel('duration')\n",
    "    plt.plot(values)\n",
    "    \n",
    "    moving_avg = get_moving_average(moving_avg_period, values)\n",
    "    plt.plot(moving_avg)\n",
    "    plt.pause(0.001)\n",
    "    print(\"Episode\", len(values), \"\\n\", moving_avg_period, \"episode moving avg:\", moving_avg[-1])\n",
    "    if is_ipython: display.clear_output(wait=True)\n",
    "        \n",
    "def get_moving_average(period, values):\n",
    "    values = torch.tensor(values, dtype=torch.float)\n",
    "    if len(values) >= period:\n",
    "        moving_avg = values.unfold(dimension=0, size=period, step=1).mean(dim=1).flatten(start_dim=0)\n",
    "        moving_avg = torch.cat((torch.zeros(period-1), moving_avg))\n",
    "        return moving_avg.numpy()\n",
    "    else: \n",
    "        moving_avg = torch.zeros(len(values))\n",
    "        return moving_avg.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QValues():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_current(policy_net, states, actions):\n",
    "        return policy_net(states).gather(dim=1, index=actions.unsqueeze(-1))\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_next(target_net, next_states):\n",
    "        final_state_locations = next_states.flatten(start_dim=1).max(dim=1)[0].eq(0).type(torch.bool)\n",
    "        non_final_state_locations = (final_state_locations == False)\n",
    "        non_final_states = next_states[non_final_state_locations]\n",
    "        batch_size = next_states.shape[0]\n",
    "        values = torch.zeros(batch_size).to(QValues.device).double()\n",
    "        values[non_final_state_locations] = target_net(non_final_states).max(dim=1)[0].detach()\n",
    "        return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.tensor(state.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = policy_net(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor(test.argmax().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.reshape(a,(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = agent.select_action(state, policy_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     def take_action(self, action):\n",
    "#         if isinstance(action, int):\n",
    "#             _, reward, self.done, _ = self.env.step(action) #.item pulls value out of tensor\n",
    "#         else:\n",
    "#             _, reward, self.done, _ = self.env.step(action.item()) #.item pulls value out of tensor\n",
    "#         return torch.tensor([reward], device=self.device) #wrapped in a tensor for pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experience = namedtuple(\n",
    "    'Experience',\n",
    "    ('state', 'action', 'next_state', 'reward')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0010)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(env.step(0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    " next_state, reward, done, _ = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = agent.select_action(state, policy_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(batch_size).to(QValues.device).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 5000 \n",
      " 100 episode moving avg: 31.55\n"
     ]
    }
   ],
   "source": [
    "episode_durations = []\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    state = torch.tensor(state.values)\n",
    "    \n",
    "    for timestep in count():\n",
    "        action = agent.select_action(state, policy_net)\n",
    "#         STOPPED HERE 20221013\n",
    "#         reward = em.take_action(action)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        reward = torch.tensor(reward)\n",
    "        reward = torch.reshape(reward, (1,))\n",
    "        next_state = torch.tensor(next_state.values)\n",
    "#         next_state = em.get_state()\n",
    "        memory.push(Experience(state, action, next_state, reward))\n",
    "        state = next_state\n",
    "        \n",
    "        if memory.can_provide_sample(batch_size):\n",
    "            experiences = memory.sample(batch_size)\n",
    "            states, actions, rewards, next_states = extract_tensors(experiences)\n",
    "            states = states.reshape(batch_size, 30) #fix this 30 with a variable\n",
    "            next_states = next_states.reshape(batch_size, 30)\n",
    "            current_q_values = QValues.get_current(policy_net, states, actions)\n",
    "            next_q_values = QValues.get_next(target_net, next_states)\n",
    "            target_q_values = (next_q_values * gamma) + rewards\n",
    "            \n",
    "            loss = F.mse_loss(current_q_values, target_q_values.unsqueeze(1))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        if env.episode_over:\n",
    "            episode_durations.append(timestep)\n",
    "            plot(episode_durations, 100)\n",
    "            break\n",
    "            \n",
    "    if episode % target_update == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "        \n",
    "# em.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1920])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_states.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEEP LIZARD CODE ABOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v0yTi3EoYgBT"
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "  def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "    self.action_size = action_size\n",
    "    self.memory = deque(maxlen=buffer_size)\n",
    "    self.batch_size = batch_size\n",
    "    self.experiences = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "    self.seed = random.seed(seed)\n",
    "  \n",
    "  def add(self, state, action, reward, next_state, done):\n",
    "    experience = self.experiences(state, action, reward, next_state, done)\n",
    "    self.memory.append(experience)\n",
    "\n",
    "  def sample(self):\n",
    "    experiences = random.sample(self.memory, k=self.batch_size)\n",
    "#     print('experiences: ', experiences)\n",
    "#     print('size 30 : ', [e for e in experiences if e.state.shape[0] == 30])\n",
    "    print(\"len(self.memory)\", len(self.memory))\n",
    "    states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).double().to(device)\n",
    "    actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).double().to(device)\n",
    "    rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).double().to(device)\n",
    "    next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).double().to(device)\n",
    "    dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None])).double().to(device)\n",
    "    return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    # experiences = random.sample(self.memory, k=BATCH_SIZE)\n",
    "\n",
    "    # batch = self.experiences(*zip(experiences))\n",
    "\n",
    "    # states = torch.cat(batch.state)\n",
    "    # actions = torch.cat(batch.actions)\n",
    "    # rewards = torch.cat(batch.reward)\n",
    "    # next_states = torch.cat(batch.next_state)\n",
    "    # dones = torch.cat(batch.done)\n",
    "    #return random.sample(self.memory, BATCH_SIZE)\n",
    "\n",
    "    \n",
    "  \n",
    "  def __len__(self):\n",
    "      return len(self.memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rfzsPcTRYWtk"
   },
   "outputs": [],
   "source": [
    "class Agent():\n",
    "  def __init__(self, action_size, seed):\n",
    "    self.action_size = action_size\n",
    "    self.seed = random.seed(seed)\n",
    "\n",
    "\n",
    "    # Q - Network\n",
    "    self.qnet_local = DQN().double().to(device)\n",
    "    self.qnet_target = DQN().double().to(device)\n",
    "    self.optimizer = optim.Adam(self.qnet_local.parameters(), lr=0.01)\n",
    "\n",
    "    self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, seed)\n",
    "\n",
    "    self.t_step = 0\n",
    "    self.train_loss = []\n",
    "\n",
    "  def step(self, state, action, reward, next_state, done):\n",
    "    self.memory.add(state, action, reward, next_state, done)\n",
    "\n",
    "\n",
    "    # learn every 4 timesteps\n",
    "    self.t_step = (self.t_step+1)%64\n",
    "    if self.t_step == 0:\n",
    "      experience = self.memory.sample()\n",
    "#       print('Experience sampled from memory : ', experience)\n",
    "      self.learn(experience, GAMMA)\n",
    "\n",
    "\n",
    "  def epsilon_greedy_action(self, state):\n",
    "    state = state.to(device)\n",
    "    self.qnet_local.eval()\n",
    "    with torch.no_grad():\n",
    "      action_values = self.qnet_local(state).max(1)[1]#.view(1, 1)\n",
    "    self.qnet_local.train()\n",
    "\n",
    "    if random.random() < 0.8:\n",
    "#       print('Predicted action based on QNetwork : ', action_values)\n",
    "      return action_values.cpu()\n",
    "    else:\n",
    "      random_action = random.choices(np.arange(self.action_size), k=BATCH_SIZE)\n",
    "#       print('Chosing  random actions for the batch : ', random_action)\n",
    "      return torch.DoubleTensor(random_action)\n",
    "  \n",
    "  def learn(self, experiences, gamma):\n",
    "    #print('Started learning')\n",
    "    states, actions, rewards, next_states, done = experiences#experiences[0].state, experiences[0].action, experiences[0].reward, experiences[0].next_state, experiences[0].done \n",
    "    criterion = torch.nn.BCELoss()\n",
    "    self.qnet_local.train()\n",
    "    self.qnet_target.eval()\n",
    "\n",
    "    #predicted_targets = self.qnet_local(states)#.gather(1, actions)\n",
    "\n",
    "    #print(next_states.view(1, 1))\n",
    "    with torch.no_grad():\n",
    "      labels_next = self.qnet_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "    \n",
    "    #print('labels_next {}'.format(labels_next))\n",
    "    \n",
    "    labels = 0 + (gamma * labels_next)\n",
    "    predicted_targets = self.qnet_local(states).gather(1, actions.long())\n",
    "\n",
    "    #print(\"Predicted targets : {}, labels : {}\".format(predicted_targets, labels))\n",
    "\n",
    "    loss = criterion(predicted_targets, labels).to(device)\n",
    "#     print(\"===========================Training loss ============================\")\n",
    "#     print(loss.item())\n",
    "    self.train_loss.append(loss.item())\n",
    "    self.optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    self.optimizer.step()\n",
    "\n",
    "    print('recent training loss : ', self.train_loss[-1])\n",
    "\n",
    "    # perform soft update\n",
    "    self.soft_update(self.qnet_local, self.qnet_target, TAU)\n",
    "  \n",
    "  def soft_update(self, local_model, target_model, tau):\n",
    "    for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "      target_param.data.copy_(tau*local_param.data + (1-tau)*target_param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v0yTi3EoYgBT"
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "  def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "    self.action_size = action_size\n",
    "    self.memory = deque(maxlen=buffer_size)\n",
    "    self.batch_size = batch_size\n",
    "    self.experiences = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "    self.seed = random.seed(seed)\n",
    "  \n",
    "  def add(self, state, action, reward, next_state, done):\n",
    "    experience = self.experiences(state, action, reward, next_state, done)\n",
    "    self.memory.append(experience)\n",
    "\n",
    "  def sample(self):\n",
    "    experiences = random.sample(self.memory, k=self.batch_size)\n",
    "#     print('experiences: ', experiences)\n",
    "#     print('size 30 : ', [e for e in experiences if e.state.shape[0] == 30])\n",
    "    print(\"len(self.memory)\", len(self.memory))\n",
    "    states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).double().to(device)\n",
    "    actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).double().to(device)\n",
    "    rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).double().to(device)\n",
    "    next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).double().to(device)\n",
    "    dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None])).double().to(device)\n",
    "    return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    # experiences = random.sample(self.memory, k=BATCH_SIZE)\n",
    "\n",
    "    # batch = self.experiences(*zip(experiences))\n",
    "\n",
    "    # states = torch.cat(batch.state)\n",
    "    # actions = torch.cat(batch.actions)\n",
    "    # rewards = torch.cat(batch.reward)\n",
    "    # next_states = torch.cat(batch.next_state)\n",
    "    # dones = torch.cat(batch.done)\n",
    "    #return random.sample(self.memory, BATCH_SIZE)\n",
    "\n",
    "    \n",
    "  \n",
    "  def __len__(self):\n",
    "      return len(self.memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vS6NkwqGYl5l"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.1, random_state=1)\n",
    "\n",
    "X_train = torch.from_numpy(X_train)\n",
    "Y_train = torch.from_numpy(Y_train).double()\n",
    "\n",
    "train = data_utils.TensorDataset(X_train, Y_train)\n",
    "train_loader = data_utils.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrand:  229448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Time      145927.000000\n",
       "V1            -2.217978\n",
       "V2             1.959408\n",
       "V3            -0.630127\n",
       "V4            -0.974365\n",
       "V5             1.155177\n",
       "V6            -0.635466\n",
       "V7             1.673501\n",
       "V8            -1.500343\n",
       "V9             1.973039\n",
       "V10            1.657137\n",
       "V11           -0.520161\n",
       "V12           -1.068451\n",
       "V13           -1.328349\n",
       "V14           -2.167184\n",
       "V15            0.233789\n",
       "V16           -0.389703\n",
       "V17            0.039867\n",
       "V18            0.016546\n",
       "V19            0.008212\n",
       "V20           -0.335358\n",
       "V21           -0.127024\n",
       "V22           -0.476486\n",
       "V23            0.094446\n",
       "V24            0.477181\n",
       "V25           -1.123183\n",
       "V26           -1.133069\n",
       "V27           -3.398807\n",
       "V28           -0.744285\n",
       "Amount         8.180000\n",
       "Name: 229448, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0cC6qla1Yqw-",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================EPOCH 0 COMPLETED===================\n",
      "Current state :  0\n",
      "env.sum_rewards:  0.0\n",
      "len(self.memory) 64\n",
      "recent training loss :  45.174145285967896\n",
      "env.sum_rewards:  -0.014000000000000005\n",
      "len(self.memory) 128\n",
      "recent training loss :  41.55828763702888\n",
      "env.sum_rewards:  -0.02000000000000001\n",
      "len(self.memory) 192\n",
      "recent training loss :  46.90830710380482\n",
      "env.sum_rewards:  0.04400000000000003\n",
      "len(self.memory) 256\n",
      "recent training loss :  37.1824340945266\n",
      "env.sum_rewards:  0.10800000000000008\n",
      "len(self.memory) 320\n",
      "recent training loss :  55.35202156726773\n",
      "env.sum_rewards:  -1.830000000000004\n",
      "len(self.memory) 384\n",
      "recent training loss :  49.47737686845167\n",
      "env.sum_rewards:  -1.7660000000000111\n",
      "len(self.memory) 448\n",
      "recent training loss :  52.516926418752725\n",
      "env.sum_rewards:  -1.768000000000011\n",
      "len(self.memory) 512\n",
      "recent training loss :  58.818449109451834\n",
      "env.sum_rewards:  -1.704000000000018\n",
      "len(self.memory) 576\n",
      "recent training loss :  60.92870339763064\n",
      "env.sum_rewards:  -1.640000000000025\n",
      "len(self.memory) 640\n",
      "recent training loss :  53.17064445303461\n",
      "env.sum_rewards:  -2.577000000000032\n",
      "len(self.memory) 704\n",
      "recent training loss :  52.484953886499845\n",
      "env.sum_rewards:  -2.513000000000039\n",
      "len(self.memory) 768\n",
      "recent training loss :  48.488416932483815\n",
      "env.sum_rewards:  -2.449000000000046\n",
      "len(self.memory) 832\n",
      "recent training loss :  43.788355255565094\n",
      "env.sum_rewards:  -2.385000000000053\n",
      "len(self.memory) 896\n",
      "recent training loss :  41.934819519578866\n",
      "env.sum_rewards:  -2.32100000000006\n",
      "len(self.memory) 960\n",
      "recent training loss :  37.197510209676594\n",
      "env.sum_rewards:  -2.257000000000067\n",
      "len(self.memory) 1024\n",
      "recent training loss :  37.08864881206141\n",
      "env.sum_rewards:  -2.269000000000066\n",
      "len(self.memory) 1088\n",
      "recent training loss :  28.178129670590593\n",
      "env.sum_rewards:  -3.2620000000000666\n",
      "len(self.memory) 1152\n",
      "recent training loss :  38.064254079823286\n",
      "env.sum_rewards:  -3.1980000000000737\n",
      "len(self.memory) 1216\n",
      "recent training loss :  27.779449339801104\n",
      "env.sum_rewards:  -3.1340000000000807\n",
      "len(self.memory) 1280\n",
      "recent training loss :  42.71842224446435\n",
      "env.sum_rewards:  -3.0700000000000878\n",
      "len(self.memory) 1344\n",
      "recent training loss :  26.377091079391217\n",
      "env.sum_rewards:  -3.006000000000095\n",
      "len(self.memory) 1408\n",
      "recent training loss :  31.05862921196366\n",
      "env.sum_rewards:  -2.942000000000102\n",
      "len(self.memory) 1472\n",
      "recent training loss :  20.299859550798264\n",
      "env.sum_rewards:  -2.878000000000109\n",
      "len(self.memory) 1536\n",
      "recent training loss :  28.07415628590062\n",
      "env.sum_rewards:  -2.814000000000116\n",
      "len(self.memory) 1600\n",
      "recent training loss :  22.927528035462345\n",
      "env.sum_rewards:  -2.8100000000001164\n",
      "len(self.memory) 1664\n",
      "recent training loss :  30.637601909415217\n",
      "env.sum_rewards:  -2.7460000000001235\n",
      "len(self.memory) 1728\n",
      "recent training loss :  22.628073521599084\n",
      "env.sum_rewards:  -2.6820000000001305\n",
      "len(self.memory) 1792\n",
      "recent training loss :  24.440606831935593\n",
      "env.sum_rewards:  -2.6840000000001303\n",
      "len(self.memory) 1856\n",
      "recent training loss :  32.335874911045195\n",
      "env.sum_rewards:  -2.6200000000001373\n",
      "len(self.memory) 1920\n",
      "recent training loss :  23.35391755066699\n",
      "env.sum_rewards:  -2.5560000000001444\n",
      "len(self.memory) 1984\n",
      "recent training loss :  26.234501599280115\n",
      "env.sum_rewards:  -2.4920000000001514\n",
      "len(self.memory) 2048\n",
      "recent training loss :  27.97306439386506\n",
      "env.sum_rewards:  -2.4280000000001585\n",
      "len(self.memory) 2112\n",
      "recent training loss :  20.42231797562421\n",
      "env.sum_rewards:  -2.3640000000001655\n",
      "len(self.memory) 2176\n",
      "recent training loss :  26.76902937107613\n",
      "env.sum_rewards:  -2.3000000000001726\n",
      "len(self.memory) 2240\n",
      "recent training loss :  15.88365100743199\n",
      "env.sum_rewards:  -2.3100000000001715\n",
      "len(self.memory) 2304\n",
      "recent training loss :  16.239555549922798\n",
      "env.sum_rewards:  -2.2460000000001785\n",
      "len(self.memory) 2368\n",
      "recent training loss :  9.194966367838378\n",
      "env.sum_rewards:  -2.240000000000179\n",
      "len(self.memory) 2432\n",
      "recent training loss :  18.1075666709842\n",
      "env.sum_rewards:  -2.1760000000001862\n",
      "len(self.memory) 2496\n",
      "recent training loss :  13.363822625725485\n",
      "env.sum_rewards:  -2.1120000000001933\n",
      "len(self.memory) 2560\n",
      "recent training loss :  28.0134046111589\n",
      "env.sum_rewards:  -3.095000000000195\n",
      "len(self.memory) 2624\n",
      "recent training loss :  15.527130553807577\n",
      "env.sum_rewards:  -3.031000000000202\n",
      "len(self.memory) 2688\n",
      "recent training loss :  10.340711264610906\n",
      "env.sum_rewards:  -2.9670000000002092\n",
      "len(self.memory) 2752\n",
      "recent training loss :  23.693528817067655\n",
      "env.sum_rewards:  -2.9650000000002095\n",
      "len(self.memory) 2816\n",
      "recent training loss :  15.369184979745633\n",
      "env.sum_rewards:  -2.9010000000002165\n",
      "len(self.memory) 2880\n",
      "recent training loss :  14.514631171136008\n",
      "env.sum_rewards:  -2.8370000000002236\n",
      "len(self.memory) 2944\n",
      "recent training loss :  17.037862078989946\n",
      "env.sum_rewards:  -2.7730000000002306\n",
      "len(self.memory) 3008\n",
      "recent training loss :  22.621439880355865\n",
      "env.sum_rewards:  -2.7090000000002377\n",
      "len(self.memory) 3072\n",
      "recent training loss :  12.97400348459433\n",
      "env.sum_rewards:  -2.6450000000002447\n",
      "len(self.memory) 3136\n",
      "recent training loss :  16.168531212487874\n",
      "env.sum_rewards:  -2.635000000000246\n",
      "len(self.memory) 3200\n",
      "recent training loss :  10.903091439135085\n",
      "env.sum_rewards:  -2.571000000000253\n",
      "len(self.memory) 3264\n",
      "recent training loss :  13.468338194449123\n",
      "env.sum_rewards:  -2.50700000000026\n",
      "len(self.memory) 3328\n",
      "recent training loss :  18.052324002448973\n",
      "env.sum_rewards:  -2.443000000000267\n",
      "len(self.memory) 3392\n",
      "recent training loss :  15.44834069404906\n",
      "env.sum_rewards:  -2.443000000000267\n",
      "len(self.memory) 3456\n",
      "recent training loss :  7.5344748493858535\n",
      "env.sum_rewards:  -2.379000000000274\n",
      "len(self.memory) 3520\n",
      "recent training loss :  10.258837768108705\n",
      "env.sum_rewards:  -2.315000000000281\n",
      "len(self.memory) 3584\n",
      "recent training loss :  6.444944312479017\n",
      "env.sum_rewards:  -2.251000000000288\n",
      "len(self.memory) 3648\n",
      "recent training loss :  9.347817399161139\n",
      "env.sum_rewards:  -2.2490000000002883\n",
      "len(self.memory) 3712\n",
      "recent training loss :  4.288213336358479\n",
      "env.sum_rewards:  -2.1850000000002954\n",
      "len(self.memory) 3776\n",
      "recent training loss :  3.962413205475518\n",
      "env.sum_rewards:  -2.1210000000003024\n",
      "len(self.memory) 3840\n",
      "recent training loss :  10.405334432492957\n",
      "env.sum_rewards:  -3.0580000000003094\n",
      "len(self.memory) 3904\n",
      "recent training loss :  3.364768381043909\n",
      "env.sum_rewards:  -2.9940000000003164\n",
      "len(self.memory) 3968\n",
      "recent training loss :  11.824626593194449\n",
      "env.sum_rewards:  -2.9860000000003173\n",
      "len(self.memory) 4032\n",
      "recent training loss :  7.836800660546313\n",
      "env.sum_rewards:  -2.9820000000003177\n",
      "len(self.memory) 4096\n",
      "recent training loss :  10.242188356880224\n",
      "env.sum_rewards:  -2.918000000000325\n",
      "len(self.memory) 4160\n",
      "recent training loss :  4.30899784748857\n",
      "env.sum_rewards:  -2.854000000000332\n",
      "len(self.memory) 4224\n",
      "recent training loss :  4.0936374307087515\n",
      "env.sum_rewards:  -2.790000000000339\n",
      "len(self.memory) 4288\n",
      "recent training loss :  4.1146039356576996\n",
      "env.sum_rewards:  -2.726000000000346\n",
      "len(self.memory) 4352\n",
      "recent training loss :  9.370216199168347\n",
      "env.sum_rewards:  -2.662000000000353\n",
      "len(self.memory) 4416\n",
      "recent training loss :  5.218616632328146\n",
      "env.sum_rewards:  -2.670000000000352\n",
      "len(self.memory) 4480\n",
      "recent training loss :  2.641631035450811\n",
      "env.sum_rewards:  -2.606000000000359\n",
      "len(self.memory) 4544\n",
      "recent training loss :  5.1427928218211285\n",
      "env.sum_rewards:  -2.618000000000358\n",
      "len(self.memory) 4608\n",
      "recent training loss :  9.66283264972178\n",
      "env.sum_rewards:  -2.554000000000365\n",
      "len(self.memory) 4672\n",
      "recent training loss :  6.842705479669679\n",
      "env.sum_rewards:  -2.490000000000372\n",
      "len(self.memory) 4736\n",
      "recent training loss :  11.219355430338727\n",
      "env.sum_rewards:  -2.426000000000379\n",
      "len(self.memory) 4800\n",
      "recent training loss :  2.3430015898928223\n",
      "env.sum_rewards:  -2.362000000000386\n",
      "len(self.memory) 4864\n",
      "recent training loss :  5.922504547544826\n",
      "env.sum_rewards:  -2.298000000000393\n",
      "len(self.memory) 4928\n",
      "recent training loss :  7.175188206788674\n",
      "env.sum_rewards:  -2.2340000000004\n",
      "len(self.memory) 4992\n",
      "recent training loss :  4.0888284776208925\n",
      "env.sum_rewards:  -2.2380000000003997\n",
      "len(self.memory) 5056\n",
      "recent training loss :  7.210036777680816\n",
      "env.sum_rewards:  -2.1740000000004067\n",
      "len(self.memory) 5120\n",
      "recent training loss :  2.7281093414225532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env.sum_rewards:  -2.1100000000004138\n",
      "len(self.memory) 5184\n",
      "recent training loss :  9.79517598006879\n",
      "env.sum_rewards:  -3.0470000000004207\n",
      "len(self.memory) 5248\n",
      "recent training loss :  8.726945722511994\n",
      "env.sum_rewards:  -4.9850000000004\n",
      "len(self.memory) 5312\n",
      "recent training loss :  4.0875509863658195\n",
      "env.sum_rewards:  -5.922000000000379\n",
      "len(self.memory) 5376\n",
      "recent training loss :  4.628384255620381\n",
      "env.sum_rewards:  -5.858000000000358\n",
      "len(self.memory) 5440\n",
      "recent training loss :  2.5295511607918373\n",
      "env.sum_rewards:  -5.846000000000354\n",
      "len(self.memory) 5504\n",
      "recent training loss :  4.035701613370817\n",
      "env.sum_rewards:  -5.782000000000332\n",
      "len(self.memory) 5568\n",
      "recent training loss :  5.981511194211567\n",
      "env.sum_rewards:  -5.782000000000332\n",
      "len(self.memory) 5632\n",
      "recent training loss :  8.728707981327533\n",
      "env.sum_rewards:  -5.7920000000003355\n",
      "len(self.memory) 5696\n",
      "recent training loss :  5.732225272964394\n",
      "env.sum_rewards:  -5.728000000000314\n",
      "len(self.memory) 5760\n",
      "recent training loss :  5.640690009304021\n",
      "env.sum_rewards:  -5.664000000000293\n",
      "len(self.memory) 5824\n",
      "recent training loss :  8.814174728784817\n",
      "env.sum_rewards:  -5.600000000000271\n",
      "len(self.memory) 5888\n",
      "recent training loss :  10.15114319187503\n",
      "env.sum_rewards:  -5.53600000000025\n",
      "len(self.memory) 5952\n",
      "recent training loss :  12.13294426564895\n",
      "env.sum_rewards:  -5.472000000000229\n",
      "len(self.memory) 6016\n",
      "recent training loss :  6.42262496149196\n",
      "env.sum_rewards:  -5.456000000000223\n",
      "len(self.memory) 6080\n",
      "recent training loss :  7.320914284245873\n",
      "env.sum_rewards:  -5.392000000000202\n",
      "len(self.memory) 6144\n",
      "recent training loss :  20.316668530991247\n",
      "env.sum_rewards:  -5.328000000000181\n",
      "len(self.memory) 6208\n",
      "recent training loss :  8.005943225955882\n",
      "env.sum_rewards:  -8.26700000000017\n",
      "len(self.memory) 6272\n",
      "recent training loss :  19.493055763859747\n",
      "env.sum_rewards:  -8.203000000000205\n",
      "len(self.memory) 6336\n",
      "recent training loss :  8.750326996841757\n",
      "env.sum_rewards:  -8.139000000000241\n",
      "len(self.memory) 6400\n",
      "recent training loss :  7.720838333879018\n",
      "env.sum_rewards:  -8.075000000000276\n",
      "len(self.memory) 6464\n",
      "recent training loss :  15.31313821858975\n",
      "env.sum_rewards:  -8.073000000000278\n",
      "len(self.memory) 6528\n",
      "recent training loss :  9.725723688360809\n",
      "env.sum_rewards:  -8.081000000000273\n",
      "len(self.memory) 6592\n",
      "recent training loss :  12.679658798048631\n",
      "env.sum_rewards:  -8.091000000000268\n",
      "len(self.memory) 6656\n",
      "recent training loss :  11.145329992106038\n",
      "env.sum_rewards:  -8.027000000000303\n",
      "len(self.memory) 6720\n",
      "recent training loss :  14.668738194831873\n",
      "env.sum_rewards:  -7.963000000000306\n",
      "len(self.memory) 6784\n",
      "recent training loss :  12.449172574705226\n",
      "env.sum_rewards:  -7.899000000000284\n",
      "len(self.memory) 6848\n",
      "recent training loss :  14.51140673037885\n",
      "env.sum_rewards:  -7.835000000000263\n",
      "len(self.memory) 6912\n",
      "recent training loss :  11.750507081252797\n",
      "env.sum_rewards:  -7.7710000000002415\n",
      "len(self.memory) 6976\n",
      "recent training loss :  16.29595575802743\n",
      "env.sum_rewards:  -7.70700000000022\n",
      "len(self.memory) 7040\n",
      "recent training loss :  7.18388813356589\n",
      "env.sum_rewards:  -7.643000000000199\n",
      "len(self.memory) 7104\n",
      "recent training loss :  15.061021043148335\n",
      "env.sum_rewards:  -7.579000000000177\n",
      "len(self.memory) 7168\n",
      "recent training loss :  13.391510887155537\n",
      "env.sum_rewards:  -7.515000000000156\n",
      "len(self.memory) 7232\n",
      "recent training loss :  13.347837580884192\n",
      "env.sum_rewards:  -7.451000000000135\n",
      "len(self.memory) 7296\n",
      "recent training loss :  16.469645018984234\n",
      "env.sum_rewards:  -7.387000000000113\n",
      "len(self.memory) 7360\n",
      "recent training loss :  11.674756181410654\n",
      "env.sum_rewards:  -7.323000000000092\n",
      "len(self.memory) 7424\n",
      "recent training loss :  10.179426609246605\n",
      "env.sum_rewards:  -7.2590000000000705\n",
      "len(self.memory) 7488\n",
      "recent training loss :  15.437340443073914\n",
      "env.sum_rewards:  -7.195000000000049\n",
      "len(self.memory) 7552\n",
      "recent training loss :  14.923981728128796\n",
      "env.sum_rewards:  -7.131000000000028\n",
      "len(self.memory) 7616\n",
      "recent training loss :  10.260468606283041\n",
      "env.sum_rewards:  -7.067000000000006\n",
      "len(self.memory) 7680\n",
      "recent training loss :  13.79309875249718\n",
      "env.sum_rewards:  -8.078000000000007\n",
      "len(self.memory) 7744\n",
      "recent training loss :  15.106086718944347\n",
      "env.sum_rewards:  -8.084000000000003\n",
      "len(self.memory) 7808\n",
      "recent training loss :  10.27931269749837\n",
      "env.sum_rewards:  -8.020000000000039\n",
      "len(self.memory) 7872\n",
      "recent training loss :  10.226978530807028\n",
      "env.sum_rewards:  -8.012000000000043\n",
      "len(self.memory) 7936\n",
      "recent training loss :  10.281246365601842\n",
      "env.sum_rewards:  -7.948000000000032\n",
      "len(self.memory) 8000\n",
      "recent training loss :  15.075467491047705\n",
      "env.sum_rewards:  -8.88500000000003\n",
      "len(self.memory) 8064\n",
      "recent training loss :  21.956012587344283\n",
      "env.sum_rewards:  -8.881000000000032\n",
      "len(self.memory) 8128\n",
      "recent training loss :  17.19235060806387\n",
      "env.sum_rewards:  -8.817000000000068\n",
      "len(self.memory) 8192\n",
      "recent training loss :  14.878810388768287\n",
      "env.sum_rewards:  -8.753000000000103\n",
      "len(self.memory) 8256\n",
      "recent training loss :  18.736477390521213\n",
      "env.sum_rewards:  -8.761000000000099\n",
      "len(self.memory) 8320\n",
      "recent training loss :  13.397077545681077\n",
      "env.sum_rewards:  -8.757000000000101\n",
      "len(self.memory) 8384\n",
      "recent training loss :  11.697525167670156\n",
      "env.sum_rewards:  -8.693000000000136\n",
      "len(self.memory) 8448\n",
      "recent training loss :  17.33249147065182\n",
      "env.sum_rewards:  -8.629000000000172\n",
      "len(self.memory) 8512\n",
      "recent training loss :  11.43821903369214\n",
      "env.sum_rewards:  -8.565000000000207\n",
      "len(self.memory) 8576\n",
      "recent training loss :  12.744540277288216\n",
      "env.sum_rewards:  -8.565000000000207\n",
      "len(self.memory) 8640\n",
      "recent training loss :  13.143647596424696\n",
      "env.sum_rewards:  -8.573000000000203\n",
      "len(self.memory) 8704\n",
      "recent training loss :  14.894732643240358\n",
      "env.sum_rewards:  -8.509000000000238\n",
      "len(self.memory) 8768\n",
      "recent training loss :  19.49208641827956\n",
      "env.sum_rewards:  -8.445000000000274\n",
      "len(self.memory) 8832\n",
      "recent training loss :  14.753471472477838\n",
      "env.sum_rewards:  -9.382000000000309\n",
      "len(self.memory) 8896\n",
      "recent training loss :  11.828514851427226\n",
      "env.sum_rewards:  -9.318000000000344\n",
      "len(self.memory) 8960\n",
      "recent training loss :  9.824040654521832\n",
      "env.sum_rewards:  -10.25500000000038\n",
      "len(self.memory) 9024\n",
      "recent training loss :  10.228884991879275\n",
      "env.sum_rewards:  -11.25200000000038\n",
      "len(self.memory) 9088\n",
      "recent training loss :  15.0651683517065\n",
      "env.sum_rewards:  -11.188000000000416\n",
      "len(self.memory) 9152\n",
      "recent training loss :  13.453043320629014\n",
      "env.sum_rewards:  -11.124000000000452\n",
      "len(self.memory) 9216\n",
      "recent training loss :  15.058539253307245\n",
      "env.sum_rewards:  -11.060000000000487\n",
      "len(self.memory) 9280\n",
      "recent training loss :  14.89577121647283\n",
      "env.sum_rewards:  -10.996000000000523\n",
      "len(self.memory) 9344\n",
      "recent training loss :  14.243885390521648\n",
      "env.sum_rewards:  -10.932000000000558\n",
      "len(self.memory) 9408\n",
      "recent training loss :  15.885272538749991\n",
      "env.sum_rewards:  -10.868000000000594\n",
      "len(self.memory) 9472\n",
      "recent training loss :  13.536521520762662\n",
      "env.sum_rewards:  -10.804000000000629\n",
      "len(self.memory) 9536\n",
      "recent training loss :  7.180505855886603\n",
      "env.sum_rewards:  -10.740000000000665\n",
      "len(self.memory) 9600\n",
      "recent training loss :  17.63124187903825\n",
      "env.sum_rewards:  -10.6760000000007\n",
      "len(self.memory) 9664\n",
      "recent training loss :  14.724367503963872\n",
      "env.sum_rewards:  -10.674000000000701\n",
      "len(self.memory) 9728\n",
      "recent training loss :  25.170335561885967\n",
      "env.sum_rewards:  -10.674000000000701\n",
      "len(self.memory) 9792\n",
      "recent training loss :  11.85576362451539\n",
      "env.sum_rewards:  -10.662000000000708\n",
      "len(self.memory) 9856\n",
      "recent training loss :  23.41836655064735\n",
      "env.sum_rewards:  -10.660000000000709\n",
      "len(self.memory) 9920\n",
      "recent training loss :  13.452004571673033\n",
      "env.sum_rewards:  -10.596000000000744\n",
      "len(self.memory) 9984\n",
      "recent training loss :  13.899299202877677\n",
      "env.sum_rewards:  -10.600000000000742\n",
      "len(self.memory) 10048\n",
      "recent training loss :  11.550062973804886\n",
      "env.sum_rewards:  -10.536000000000778\n",
      "len(self.memory) 10112\n",
      "recent training loss :  16.84651888278537\n",
      "env.sum_rewards:  -12.474000000000812\n",
      "len(self.memory) 10176\n",
      "recent training loss :  14.918147016165152\n",
      "env.sum_rewards:  -12.480000000000809\n",
      "len(self.memory) 10240\n",
      "recent training loss :  16.42227758802451\n",
      "env.sum_rewards:  -12.416000000000844\n",
      "len(self.memory) 10304\n",
      "recent training loss :  12.697206656628673\n",
      "env.sum_rewards:  -12.35200000000088\n",
      "len(self.memory) 10368\n",
      "recent training loss :  17.419510934113532\n",
      "env.sum_rewards:  -12.35000000000088\n",
      "len(self.memory) 10432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recent training loss :  7.793039078032985\n",
      "env.sum_rewards:  -12.286000000000916\n",
      "len(self.memory) 10496\n",
      "recent training loss :  19.17629880805411\n",
      "env.sum_rewards:  -12.222000000000952\n",
      "len(self.memory) 10560\n",
      "recent training loss :  24.180557310676296\n",
      "env.sum_rewards:  -12.158000000000987\n",
      "len(self.memory) 10624\n",
      "recent training loss :  23.004526903623248\n",
      "env.sum_rewards:  -12.094000000001023\n",
      "len(self.memory) 10688\n",
      "recent training loss :  15.061133020310585\n",
      "env.sum_rewards:  -12.030000000001058\n",
      "len(self.memory) 10752\n",
      "recent training loss :  16.207560953128908\n",
      "env.sum_rewards:  -11.966000000001094\n",
      "len(self.memory) 10816\n",
      "recent training loss :  12.128934640510035\n",
      "env.sum_rewards:  -12.903000000001128\n",
      "len(self.memory) 10880\n",
      "recent training loss :  16.458744268200967\n",
      "env.sum_rewards:  -12.839000000001164\n",
      "len(self.memory) 10944\n",
      "recent training loss :  24.058597403038995\n",
      "env.sum_rewards:  -12.7750000000012\n",
      "len(self.memory) 11008\n",
      "recent training loss :  19.1853279089626\n",
      "env.sum_rewards:  -12.779000000001197\n",
      "len(self.memory) 11072\n",
      "recent training loss :  13.194500877174352\n",
      "env.sum_rewards:  -12.715000000001233\n",
      "len(self.memory) 11136\n",
      "recent training loss :  15.168225225086335\n",
      "env.sum_rewards:  -12.651000000001268\n",
      "len(self.memory) 11200\n",
      "recent training loss :  7.964437990420409\n",
      "env.sum_rewards:  -12.587000000001304\n",
      "len(self.memory) 11264\n",
      "recent training loss :  22.646477646485316\n",
      "env.sum_rewards:  -12.523000000001339\n",
      "len(self.memory) 11328\n",
      "recent training loss :  17.76189901603692\n",
      "env.sum_rewards:  -12.459000000001375\n",
      "len(self.memory) 11392\n",
      "recent training loss :  14.040161656021645\n",
      "env.sum_rewards:  -12.39500000000141\n",
      "len(self.memory) 11456\n",
      "recent training loss :  12.96868963006828\n",
      "env.sum_rewards:  -12.393000000001411\n",
      "len(self.memory) 11520\n",
      "recent training loss :  17.945109612251105\n",
      "env.sum_rewards:  -12.329000000001447\n",
      "len(self.memory) 11584\n",
      "recent training loss :  24.520580424285896\n",
      "env.sum_rewards:  -12.265000000001482\n",
      "len(self.memory) 11648\n",
      "recent training loss :  15.93901275859109\n",
      "env.sum_rewards:  -12.201000000001518\n",
      "len(self.memory) 11712\n",
      "recent training loss :  18.00964598266203\n",
      "env.sum_rewards:  -12.137000000001553\n",
      "len(self.memory) 11776\n",
      "recent training loss :  19.055319225757952\n",
      "env.sum_rewards:  -12.073000000001588\n",
      "len(self.memory) 11840\n",
      "recent training loss :  16.4468642386124\n",
      "env.sum_rewards:  -13.010000000001623\n",
      "len(self.memory) 11904\n",
      "recent training loss :  18.56661748828693\n",
      "env.sum_rewards:  -12.948000000001658\n",
      "len(self.memory) 11968\n",
      "recent training loss :  12.022682334887888\n",
      "env.sum_rewards:  -12.884000000001693\n",
      "len(self.memory) 12032\n",
      "recent training loss :  15.690449714777149\n",
      "env.sum_rewards:  -13.821000000001728\n",
      "len(self.memory) 12096\n",
      "recent training loss :  13.752966003353809\n",
      "env.sum_rewards:  -13.757000000001764\n",
      "len(self.memory) 12160\n",
      "recent training loss :  14.927727599233545\n",
      "env.sum_rewards:  -13.693000000001799\n",
      "len(self.memory) 12224\n",
      "recent training loss :  15.107467809754105\n",
      "env.sum_rewards:  -13.629000000001835\n",
      "len(self.memory) 12288\n",
      "recent training loss :  11.03350577801911\n",
      "env.sum_rewards:  -13.56500000000187\n",
      "len(self.memory) 12352\n",
      "recent training loss :  16.310343074062068\n",
      "env.sum_rewards:  -13.501000000001905\n",
      "len(self.memory) 12416\n",
      "recent training loss :  10.10502531903969\n",
      "env.sum_rewards:  -13.437000000001941\n",
      "len(self.memory) 12480\n",
      "recent training loss :  25.81660604055967\n",
      "env.sum_rewards:  -13.435000000001942\n",
      "len(self.memory) 12544\n",
      "recent training loss :  21.156429222182208\n",
      "env.sum_rewards:  -13.371000000001978\n",
      "len(self.memory) 12608\n",
      "recent training loss :  20.495985191465138\n",
      "env.sum_rewards:  -13.307000000002013\n",
      "len(self.memory) 12672\n",
      "recent training loss :  22.56140136198119\n",
      "env.sum_rewards:  -13.243000000002048\n",
      "len(self.memory) 12736\n",
      "recent training loss :  19.410719740748213\n",
      "env.sum_rewards:  -13.179000000002084\n",
      "len(self.memory) 12800\n",
      "recent training loss :  17.772331890266745\n",
      "env.sum_rewards:  -13.11500000000212\n",
      "len(self.memory) 12864\n",
      "recent training loss :  19.570100057141417\n",
      "env.sum_rewards:  -13.123000000002115\n",
      "len(self.memory) 12928\n",
      "recent training loss :  11.327553001933\n",
      "env.sum_rewards:  -13.05900000000215\n",
      "len(self.memory) 12992\n",
      "recent training loss :  14.908170883670056\n",
      "env.sum_rewards:  -12.995000000002186\n",
      "len(self.memory) 13056\n",
      "recent training loss :  11.90050968733405\n",
      "env.sum_rewards:  -12.931000000002221\n",
      "len(self.memory) 13120\n",
      "recent training loss :  14.339465624287337\n",
      "env.sum_rewards:  -12.867000000002257\n",
      "len(self.memory) 13184\n",
      "recent training loss :  17.941607464195755\n",
      "env.sum_rewards:  -12.803000000002292\n",
      "len(self.memory) 13248\n",
      "recent training loss :  14.943438765177978\n",
      "env.sum_rewards:  -12.739000000002328\n",
      "len(self.memory) 13312\n",
      "recent training loss :  13.16704837255752\n",
      "env.sum_rewards:  -12.675000000002363\n",
      "len(self.memory) 13376\n",
      "recent training loss :  11.833903819091626\n",
      "env.sum_rewards:  -12.611000000002399\n",
      "len(self.memory) 13440\n",
      "recent training loss :  14.958525649447864\n",
      "env.sum_rewards:  -12.547000000002434\n",
      "len(self.memory) 13504\n",
      "recent training loss :  16.77278256568281\n",
      "env.sum_rewards:  -12.48300000000247\n",
      "len(self.memory) 13568\n",
      "recent training loss :  17.619731919475054\n",
      "env.sum_rewards:  -12.419000000002505\n",
      "len(self.memory) 13632\n",
      "recent training loss :  13.51468778420281\n",
      "env.sum_rewards:  -12.35500000000254\n",
      "len(self.memory) 13696\n",
      "recent training loss :  17.903506358969167\n",
      "env.sum_rewards:  -12.291000000002576\n",
      "len(self.memory) 13760\n",
      "recent training loss :  10.281642318678887\n",
      "env.sum_rewards:  -12.293000000002575\n",
      "len(self.memory) 13824\n",
      "recent training loss :  25.811441011492533\n",
      "env.sum_rewards:  -12.22900000000261\n",
      "len(self.memory) 13888\n",
      "recent training loss :  24.3235932863371\n",
      "env.sum_rewards:  -12.233000000002608\n",
      "len(self.memory) 13952\n",
      "recent training loss :  18.00980635758957\n",
      "env.sum_rewards:  -13.170000000002643\n",
      "len(self.memory) 14016\n",
      "recent training loss :  16.350248687614716\n",
      "env.sum_rewards:  -13.106000000002679\n",
      "len(self.memory) 14080\n",
      "recent training loss :  19.78067616158325\n",
      "env.sum_rewards:  -13.042000000002714\n",
      "len(self.memory) 14144\n",
      "recent training loss :  21.11376069252004\n",
      "env.sum_rewards:  -13.979000000002749\n",
      "len(self.memory) 14208\n",
      "recent training loss :  7.193880279280956\n",
      "env.sum_rewards:  -13.915000000002784\n",
      "len(self.memory) 14272\n",
      "recent training loss :  8.728320592730551\n",
      "env.sum_rewards:  -12.90600000000279\n",
      "len(self.memory) 14336\n",
      "recent training loss :  16.426328733328248\n",
      "env.sum_rewards:  -11.919000000002782\n",
      "len(self.memory) 14400\n",
      "recent training loss :  22.6481255074823\n",
      "env.sum_rewards:  -11.855000000002818\n",
      "len(self.memory) 14464\n",
      "recent training loss :  12.691915235025855\n",
      "env.sum_rewards:  -12.792000000002853\n",
      "len(self.memory) 14528\n",
      "recent training loss :  21.08845891110174\n",
      "env.sum_rewards:  -12.804000000002846\n",
      "len(self.memory) 14592\n",
      "recent training loss :  18.09983178685393\n",
      "env.sum_rewards:  -13.741000000002881\n",
      "len(self.memory) 14656\n",
      "recent training loss :  16.452040368138686\n",
      "env.sum_rewards:  -13.677000000002916\n",
      "len(self.memory) 14720\n",
      "recent training loss :  24.248986970832348\n",
      "env.sum_rewards:  -13.613000000002952\n",
      "len(self.memory) 14784\n",
      "recent training loss :  16.468623703742534\n",
      "env.sum_rewards:  -13.549000000002987\n",
      "len(self.memory) 14848\n",
      "recent training loss :  13.359057325309655\n",
      "env.sum_rewards:  -13.485000000003023\n",
      "len(self.memory) 14912\n",
      "recent training loss :  19.883112452614107\n",
      "env.sum_rewards:  -14.422000000003058\n",
      "len(self.memory) 14976\n",
      "recent training loss :  25.291315727436736\n",
      "env.sum_rewards:  -14.426000000003055\n",
      "len(self.memory) 15040\n",
      "recent training loss :  26.060167274700056\n",
      "env.sum_rewards:  -14.362000000003091\n",
      "len(self.memory) 15104\n",
      "recent training loss :  21.179894740486237\n",
      "env.sum_rewards:  -14.298000000003126\n",
      "len(self.memory) 15168\n",
      "recent training loss :  16.915489101577183\n",
      "env.sum_rewards:  -14.294000000003129\n",
      "len(self.memory) 15232\n",
      "recent training loss :  27.161096855926303\n",
      "env.sum_rewards:  -14.230000000003164\n",
      "len(self.memory) 15296\n",
      "recent training loss :  18.058289769903908\n",
      "env.sum_rewards:  -14.1660000000032\n",
      "len(self.memory) 15360\n",
      "recent training loss :  20.948002604748496\n",
      "env.sum_rewards:  -14.102000000003235\n",
      "len(self.memory) 15424\n",
      "recent training loss :  21.086838582550794\n",
      "env.sum_rewards:  -14.03800000000327\n",
      "len(self.memory) 15488\n",
      "recent training loss :  21.974347951956883\n",
      "env.sum_rewards:  -13.974000000003306\n",
      "len(self.memory) 15552\n",
      "recent training loss :  11.106276739805839\n",
      "env.sum_rewards:  -13.910000000003341\n",
      "len(self.memory) 15616\n",
      "recent training loss :  13.722451752730581\n",
      "env.sum_rewards:  -13.846000000003377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(self.memory) 15680\n",
      "recent training loss :  19.099348680117057\n",
      "env.sum_rewards:  -13.782000000003412\n",
      "len(self.memory) 15744\n",
      "recent training loss :  33.11101717925973\n",
      "env.sum_rewards:  -13.718000000003448\n",
      "len(self.memory) 15808\n",
      "recent training loss :  13.91959356768997\n",
      "env.sum_rewards:  -13.720000000003447\n",
      "len(self.memory) 15872\n",
      "recent training loss :  22.647800534763988\n",
      "env.sum_rewards:  -13.656000000003482\n",
      "len(self.memory) 15936\n",
      "recent training loss :  16.987033904104575\n",
      "env.sum_rewards:  -14.64300000000349\n",
      "len(self.memory) 16000\n",
      "recent training loss :  23.51544878050829\n",
      "env.sum_rewards:  -14.649000000003486\n",
      "len(self.memory) 16064\n",
      "recent training loss :  16.768726814904383\n",
      "env.sum_rewards:  -14.585000000003522\n",
      "len(self.memory) 16128\n",
      "recent training loss :  21.163944710486867\n",
      "env.sum_rewards:  -15.522000000003557\n",
      "len(self.memory) 16192\n",
      "recent training loss :  24.381615238390623\n",
      "env.sum_rewards:  -15.458000000003592\n",
      "len(self.memory) 16256\n",
      "recent training loss :  21.977553696396733\n",
      "env.sum_rewards:  -15.394000000003627\n",
      "len(self.memory) 16320\n",
      "recent training loss :  23.58422921123886\n",
      "env.sum_rewards:  -15.386000000003632\n",
      "len(self.memory) 16384\n",
      "recent training loss :  19.16068756920636\n",
      "env.sum_rewards:  -15.376000000003637\n",
      "len(self.memory) 16448\n",
      "recent training loss :  21.023364153733144\n",
      "env.sum_rewards:  -15.312000000003673\n",
      "len(self.memory) 16512\n",
      "recent training loss :  31.438439588529157\n",
      "env.sum_rewards:  -15.248000000003708\n",
      "len(self.memory) 16576\n",
      "recent training loss :  23.70866026557276\n",
      "env.sum_rewards:  -15.184000000003744\n",
      "len(self.memory) 16640\n",
      "recent training loss :  21.384271196099892\n",
      "env.sum_rewards:  -15.12000000000378\n",
      "len(self.memory) 16704\n",
      "recent training loss :  27.02609859423295\n",
      "env.sum_rewards:  -15.056000000003815\n",
      "len(self.memory) 16768\n",
      "recent training loss :  27.199626654773624\n",
      "env.sum_rewards:  -14.99200000000385\n",
      "len(self.memory) 16832\n",
      "recent training loss :  22.45818346281824\n",
      "env.sum_rewards:  -14.928000000003886\n",
      "len(self.memory) 16896\n",
      "recent training loss :  21.130154998845825\n",
      "env.sum_rewards:  -14.864000000003921\n",
      "len(self.memory) 16960\n",
      "recent training loss :  27.178731136814267\n",
      "env.sum_rewards:  -14.800000000003957\n",
      "len(self.memory) 17024\n",
      "recent training loss :  24.227614003210988\n",
      "env.sum_rewards:  -14.736000000003992\n",
      "len(self.memory) 17088\n",
      "recent training loss :  23.851135496461747\n",
      "env.sum_rewards:  -14.672000000004028\n",
      "len(self.memory) 17152\n",
      "recent training loss :  15.490489544486802\n",
      "env.sum_rewards:  -14.608000000004063\n",
      "len(self.memory) 17216\n",
      "recent training loss :  24.514442784794678\n",
      "env.sum_rewards:  -14.544000000004099\n",
      "len(self.memory) 17280\n",
      "recent training loss :  24.144951659200593\n",
      "env.sum_rewards:  -14.480000000004134\n",
      "len(self.memory) 17344\n",
      "recent training loss :  22.62410532228965\n",
      "env.sum_rewards:  -14.41600000000417\n",
      "len(self.memory) 17408\n",
      "recent training loss :  18.009726150257112\n",
      "env.sum_rewards:  -14.418000000004168\n",
      "len(self.memory) 17472\n",
      "recent training loss :  22.982904836624954\n",
      "env.sum_rewards:  -14.354000000004204\n",
      "len(self.memory) 17536\n",
      "recent training loss :  23.211349292863705\n",
      "env.sum_rewards:  -14.34200000000421\n",
      "len(self.memory) 17600\n",
      "recent training loss :  21.045415278243155\n",
      "env.sum_rewards:  -14.348000000004207\n",
      "len(self.memory) 17664\n",
      "recent training loss :  24.983858448331773\n",
      "env.sum_rewards:  -14.338000000004213\n",
      "len(self.memory) 17728\n",
      "recent training loss :  26.835744165493363\n",
      "env.sum_rewards:  -14.274000000004248\n",
      "len(self.memory) 17792\n",
      "recent training loss :  21.17374863921081\n",
      "env.sum_rewards:  -14.210000000004284\n",
      "len(self.memory) 17856\n",
      "recent training loss :  31.779564825185886\n",
      "env.sum_rewards:  -14.14600000000432\n",
      "len(self.memory) 17920\n",
      "recent training loss :  34.6202538123198\n",
      "env.sum_rewards:  -14.152000000004316\n",
      "len(self.memory) 17984\n",
      "recent training loss :  21.178569209999125\n",
      "env.sum_rewards:  -14.14600000000432\n",
      "len(self.memory) 18048\n",
      "recent training loss :  28.840348684855893\n",
      "env.sum_rewards:  -14.082000000004355\n",
      "len(self.memory) 18112\n",
      "recent training loss :  33.37789928417888\n",
      "env.sum_rewards:  -14.01800000000439\n",
      "len(self.memory) 18176\n",
      "recent training loss :  25.62211224796583\n",
      "env.sum_rewards:  -14.022000000004388\n",
      "len(self.memory) 18240\n",
      "recent training loss :  33.09092467596794\n",
      "env.sum_rewards:  -14.959000000004423\n",
      "len(self.memory) 18304\n",
      "recent training loss :  31.243927838096642\n",
      "env.sum_rewards:  -14.895000000004458\n",
      "len(self.memory) 18368\n",
      "recent training loss :  32.40322271161302\n",
      "env.sum_rewards:  -14.90900000000445\n",
      "len(self.memory) 18432\n",
      "recent training loss :  25.959952881773052\n",
      "env.sum_rewards:  -14.907000000004452\n",
      "len(self.memory) 18496\n",
      "recent training loss :  30.94700986668748\n",
      "env.sum_rewards:  -14.843000000004487\n",
      "len(self.memory) 18560\n",
      "recent training loss :  27.659267132881908\n",
      "env.sum_rewards:  -15.780000000004522\n",
      "len(self.memory) 18624\n",
      "recent training loss :  32.44322274413747\n",
      "env.sum_rewards:  -15.716000000004557\n",
      "len(self.memory) 18688\n",
      "recent training loss :  25.481471868595047\n",
      "env.sum_rewards:  -15.71000000000456\n",
      "len(self.memory) 18752\n",
      "recent training loss :  16.403741743920186\n",
      "env.sum_rewards:  -15.71200000000456\n",
      "len(self.memory) 18816\n",
      "recent training loss :  24.66372802509455\n",
      "env.sum_rewards:  -15.648000000004595\n",
      "len(self.memory) 18880\n",
      "recent training loss :  29.864540175155245\n",
      "env.sum_rewards:  -16.585000000004573\n",
      "len(self.memory) 18944\n",
      "recent training loss :  33.14553447063369\n",
      "env.sum_rewards:  -16.589000000004578\n",
      "len(self.memory) 19008\n",
      "recent training loss :  34.975700467193185\n",
      "env.sum_rewards:  -16.5250000000045\n",
      "len(self.memory) 19072\n",
      "recent training loss :  38.78642290194438\n",
      "env.sum_rewards:  -16.54100000000452\n",
      "len(self.memory) 19136\n",
      "recent training loss :  34.139461380323795\n",
      "env.sum_rewards:  -16.54900000000453\n",
      "len(self.memory) 19200\n",
      "recent training loss :  32.54749901014097\n",
      "env.sum_rewards:  -16.48500000000445\n",
      "len(self.memory) 19264\n",
      "recent training loss :  20.912623921330635\n",
      "env.sum_rewards:  -16.421000000004373\n",
      "len(self.memory) 19328\n",
      "recent training loss :  47.71349994490585\n",
      "env.sum_rewards:  -16.357000000004295\n",
      "len(self.memory) 19392\n",
      "recent training loss :  41.632160739203904\n",
      "env.sum_rewards:  -16.351000000004287\n",
      "len(self.memory) 19456\n",
      "recent training loss :  51.12399928700498\n",
      "env.sum_rewards:  -16.349000000004285\n",
      "len(self.memory) 19520\n",
      "recent training loss :  43.23585319751953\n",
      "env.sum_rewards:  -16.347000000004282\n",
      "len(self.memory) 19584\n",
      "recent training loss :  47.18446876040731\n",
      "env.sum_rewards:  -17.284000000004205\n",
      "len(self.memory) 19648\n",
      "recent training loss :  32.53997008639392\n",
      "env.sum_rewards:  -17.220000000004127\n",
      "len(self.memory) 19712\n",
      "recent training loss :  44.09159147846512\n",
      "env.sum_rewards:  -17.15600000000405\n",
      "len(self.memory) 19776\n",
      "recent training loss :  42.584109772194346\n",
      "env.sum_rewards:  -18.093000000003972\n",
      "len(self.memory) 19840\n",
      "recent training loss :  43.56243244951839\n",
      "env.sum_rewards:  -19.030000000003895\n",
      "len(self.memory) 19904\n",
      "recent training loss :  46.40419595994838\n",
      "env.sum_rewards:  -18.966000000003817\n",
      "len(self.memory) 19968\n",
      "recent training loss :  50.19282879042608\n",
      "env.sum_rewards:  -18.90200000000374\n",
      "len(self.memory) 20032\n",
      "recent training loss :  30.419253644762474\n",
      "env.sum_rewards:  -18.83800000000366\n",
      "len(self.memory) 20096\n",
      "recent training loss :  39.68917470435133\n",
      "env.sum_rewards:  -18.774000000003582\n",
      "len(self.memory) 20160\n",
      "recent training loss :  40.131374283464346\n",
      "env.sum_rewards:  -19.711000000003505\n",
      "len(self.memory) 20224\n",
      "recent training loss :  52.08092783857346\n",
      "env.sum_rewards:  -19.695000000003485\n",
      "len(self.memory) 20288\n",
      "recent training loss :  42.58879022016766\n",
      "env.sum_rewards:  -19.631000000003407\n",
      "len(self.memory) 20352\n",
      "recent training loss :  37.46744596666923\n",
      "env.sum_rewards:  -19.56700000000333\n",
      "len(self.memory) 20416\n",
      "recent training loss :  45.513144482075774\n",
      "env.sum_rewards:  -20.504000000003252\n",
      "len(self.memory) 20480\n",
      "recent training loss :  35.470010375567355\n",
      "env.sum_rewards:  -20.440000000003174\n",
      "len(self.memory) 20544\n",
      "recent training loss :  48.933032688703534\n",
      "env.sum_rewards:  -21.377000000003097\n",
      "len(self.memory) 20608\n",
      "recent training loss :  46.31912629656577\n",
      "env.sum_rewards:  -21.31300000000302\n",
      "len(self.memory) 20672\n",
      "recent training loss :  53.41298038630349\n",
      "env.sum_rewards:  -21.24900000000294\n",
      "len(self.memory) 20736\n",
      "recent training loss :  44.159414266464346\n",
      "env.sum_rewards:  -21.185000000002862\n",
      "len(self.memory) 20800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recent training loss :  44.8570630245048\n",
      "env.sum_rewards:  -21.121000000002784\n",
      "len(self.memory) 20864\n",
      "recent training loss :  31.76843510344096\n",
      "env.sum_rewards:  -21.1330000000028\n",
      "len(self.memory) 20928\n",
      "recent training loss :  47.980375035166794\n",
      "env.sum_rewards:  -21.06900000000272\n",
      "len(self.memory) 20992\n",
      "recent training loss :  35.61726216094425\n",
      "env.sum_rewards:  -21.005000000002642\n",
      "len(self.memory) 21056\n",
      "recent training loss :  49.99426398959771\n",
      "env.sum_rewards:  -21.00300000000264\n",
      "len(self.memory) 21120\n",
      "recent training loss :  57.73354767505181\n",
      "env.sum_rewards:  -20.93900000000256\n",
      "len(self.memory) 21184\n",
      "recent training loss :  44.774185041270535\n",
      "env.sum_rewards:  -20.875000000002483\n",
      "len(self.memory) 21248\n",
      "recent training loss :  51.1628021929419\n",
      "env.sum_rewards:  -20.811000000002405\n",
      "len(self.memory) 21312\n",
      "recent training loss :  47.65923007659189\n",
      "env.sum_rewards:  -20.747000000002327\n",
      "len(self.memory) 21376\n",
      "recent training loss :  39.543372414501974\n",
      "env.sum_rewards:  -21.68400000000225\n",
      "len(self.memory) 21440\n",
      "recent training loss :  47.114023769913985\n",
      "env.sum_rewards:  -21.62000000000217\n",
      "len(self.memory) 21504\n",
      "recent training loss :  42.384745207682734\n",
      "env.sum_rewards:  -21.556000000002093\n",
      "len(self.memory) 21568\n",
      "recent training loss :  55.674627884191025\n",
      "env.sum_rewards:  -21.492000000002015\n",
      "len(self.memory) 21632\n",
      "recent training loss :  39.984441737807664\n",
      "env.sum_rewards:  -21.428000000001937\n",
      "len(self.memory) 21696\n",
      "recent training loss :  47.59133559811186\n",
      "env.sum_rewards:  -21.36400000000186\n",
      "len(self.memory) 21760\n",
      "recent training loss :  42.859992429013744\n",
      "env.sum_rewards:  -21.30000000000178\n",
      "len(self.memory) 21824\n",
      "recent training loss :  37.749858545278876\n",
      "env.sum_rewards:  -21.236000000001702\n",
      "len(self.memory) 21888\n",
      "recent training loss :  57.16589995959718\n",
      "env.sum_rewards:  -21.248000000001717\n",
      "len(self.memory) 21952\n",
      "recent training loss :  43.57325045862856\n",
      "env.sum_rewards:  -21.18400000000164\n",
      "len(self.memory) 22016\n",
      "recent training loss :  51.49761549158389\n",
      "env.sum_rewards:  -21.12000000000156\n",
      "len(self.memory) 22080\n",
      "recent training loss :  43.56592605318122\n",
      "env.sum_rewards:  -22.057000000001484\n",
      "len(self.memory) 22144\n",
      "recent training loss :  43.42655550649216\n",
      "env.sum_rewards:  -21.993000000001405\n",
      "len(self.memory) 22208\n",
      "recent training loss :  60.48444209549784\n",
      "env.sum_rewards:  -21.929000000001327\n",
      "len(self.memory) 22272\n",
      "recent training loss :  50.69752109719205\n",
      "env.sum_rewards:  -21.86500000000125\n",
      "len(self.memory) 22336\n",
      "recent training loss :  49.60120838690746\n",
      "env.sum_rewards:  -21.861000000001244\n",
      "len(self.memory) 22400\n",
      "recent training loss :  40.34334945599866\n",
      "env.sum_rewards:  -21.797000000001166\n",
      "len(self.memory) 22464\n",
      "recent training loss :  54.67147713852635\n",
      "env.sum_rewards:  -25.737000000001093\n",
      "len(self.memory) 22528\n",
      "recent training loss :  47.75028853634778\n",
      "env.sum_rewards:  -25.673000000001014\n",
      "len(self.memory) 22592\n",
      "recent training loss :  58.27588899122692\n",
      "env.sum_rewards:  -25.609000000000936\n",
      "len(self.memory) 22656\n",
      "recent training loss :  50.98314089992185\n",
      "env.sum_rewards:  -25.545000000000858\n",
      "len(self.memory) 22720\n",
      "recent training loss :  53.848590922521964\n",
      "env.sum_rewards:  -26.48200000000078\n",
      "len(self.memory) 22784\n",
      "recent training loss :  61.544184845584475\n",
      "env.sum_rewards:  -26.470000000000766\n",
      "len(self.memory) 22848\n",
      "recent training loss :  51.78120239313664\n",
      "env.sum_rewards:  -26.406000000000688\n",
      "len(self.memory) 22912\n",
      "recent training loss :  53.916449795983226\n",
      "env.sum_rewards:  -26.34200000000061\n",
      "len(self.memory) 22976\n",
      "recent training loss :  50.82925598024072\n",
      "env.sum_rewards:  -26.27800000000053\n",
      "len(self.memory) 23040\n",
      "recent training loss :  60.46954885683947\n",
      "env.sum_rewards:  -26.272000000000524\n",
      "len(self.memory) 23104\n",
      "recent training loss :  52.19165924046685\n",
      "env.sum_rewards:  -26.28600000000054\n",
      "len(self.memory) 23168\n",
      "recent training loss :  49.12345762245593\n",
      "env.sum_rewards:  -26.222000000000463\n",
      "len(self.memory) 23232\n",
      "recent training loss :  50.259227982854206\n",
      "env.sum_rewards:  -26.158000000000385\n",
      "len(self.memory) 23296\n",
      "recent training loss :  60.8486211661232\n",
      "env.sum_rewards:  -26.094000000000307\n",
      "len(self.memory) 23360\n",
      "recent training loss :  63.01484721211766\n",
      "env.sum_rewards:  -27.03100000000023\n",
      "len(self.memory) 23424\n",
      "recent training loss :  51.79501837229123\n",
      "env.sum_rewards:  -26.96700000000015\n",
      "len(self.memory) 23488\n",
      "recent training loss :  65.33143967534139\n",
      "env.sum_rewards:  -26.903000000000073\n",
      "len(self.memory) 23552\n",
      "recent training loss :  61.623557276097365\n",
      "env.sum_rewards:  -26.838999999999995\n",
      "len(self.memory) 23616\n",
      "recent training loss :  51.70267444049555\n",
      "env.sum_rewards:  -26.774999999999917\n",
      "len(self.memory) 23680\n",
      "recent training loss :  42.88506002489916\n",
      "env.sum_rewards:  -26.71099999999984\n",
      "len(self.memory) 23744\n",
      "recent training loss :  55.47516420644101\n",
      "env.sum_rewards:  -26.64699999999976\n",
      "len(self.memory) 23808\n",
      "recent training loss :  48.06890773941691\n",
      "env.sum_rewards:  -26.63899999999975\n",
      "len(self.memory) 23872\n",
      "recent training loss :  66.41941132735012\n",
      "env.sum_rewards:  -26.574999999999672\n",
      "len(self.memory) 23936\n",
      "recent training loss :  64.63201662000314\n",
      "env.sum_rewards:  -26.510999999999594\n",
      "len(self.memory) 24000\n",
      "recent training loss :  56.46583102024626\n",
      "env.sum_rewards:  -26.446999999999516\n",
      "len(self.memory) 24064\n",
      "recent training loss :  67.61663936489684\n",
      "env.sum_rewards:  -26.382999999999438\n",
      "len(self.memory) 24128\n",
      "recent training loss :  68.21026172277537\n",
      "env.sum_rewards:  -26.382999999999438\n",
      "len(self.memory) 24192\n",
      "recent training loss :  61.96123585782198\n",
      "env.sum_rewards:  -26.31899999999936\n",
      "len(self.memory) 24256\n",
      "recent training loss :  64.14466924576534\n",
      "env.sum_rewards:  -26.25499999999928\n",
      "len(self.memory) 24320\n",
      "recent training loss :  63.93429816332538\n",
      "env.sum_rewards:  -26.190999999999203\n",
      "len(self.memory) 24384\n",
      "recent training loss :  61.758944900004735\n",
      "env.sum_rewards:  -26.126999999999125\n",
      "len(self.memory) 24448\n",
      "recent training loss :  76.21972110256797\n",
      "env.sum_rewards:  -26.062999999999047\n",
      "len(self.memory) 24512\n",
      "recent training loss :  61.354209817455384\n",
      "env.sum_rewards:  -25.99899999999897\n",
      "len(self.memory) 24576\n",
      "recent training loss :  57.52730123391963\n",
      "env.sum_rewards:  -25.93499999999889\n",
      "len(self.memory) 24640\n",
      "recent training loss :  65.89601093599258\n",
      "env.sum_rewards:  -25.870999999998812\n",
      "len(self.memory) 24704\n",
      "recent training loss :  61.03748376632056\n",
      "env.sum_rewards:  -25.806999999998734\n",
      "len(self.memory) 24768\n",
      "recent training loss :  57.90105226897722\n",
      "env.sum_rewards:  -25.742999999998656\n",
      "len(self.memory) 24832\n",
      "recent training loss :  56.37501929367572\n",
      "env.sum_rewards:  -25.742999999998656\n",
      "len(self.memory) 24896\n",
      "recent training loss :  70.00420475454374\n",
      "env.sum_rewards:  -25.678999999998577\n",
      "len(self.memory) 24960\n",
      "recent training loss :  74.30564905599567\n",
      "env.sum_rewards:  -25.682999999998582\n",
      "len(self.memory) 25024\n",
      "recent training loss :  67.68515046477079\n",
      "env.sum_rewards:  -25.618999999998504\n",
      "len(self.memory) 25088\n",
      "recent training loss :  67.90740320778966\n",
      "env.sum_rewards:  -25.628999999998516\n",
      "len(self.memory) 25152\n",
      "recent training loss :  69.46032441379536\n",
      "env.sum_rewards:  -25.628999999998516\n",
      "len(self.memory) 25216\n",
      "recent training loss :  64.38413303039577\n",
      "env.sum_rewards:  -25.564999999998438\n",
      "len(self.memory) 25280\n",
      "recent training loss :  58.24901885435741\n",
      "env.sum_rewards:  -25.50099999999836\n",
      "len(self.memory) 25344\n",
      "recent training loss :  74.72614021383193\n",
      "env.sum_rewards:  -25.43699999999828\n",
      "len(self.memory) 25408\n",
      "recent training loss :  68.3941269254262\n",
      "env.sum_rewards:  -25.43699999999828\n",
      "len(self.memory) 25472\n",
      "recent training loss :  61.022830986826804\n",
      "env.sum_rewards:  -25.372999999998203\n",
      "len(self.memory) 25536\n",
      "recent training loss :  71.5897638749252\n",
      "env.sum_rewards:  -25.364999999998194\n",
      "len(self.memory) 25600\n",
      "recent training loss :  72.52549369047182\n",
      "env.sum_rewards:  -25.300999999998115\n",
      "len(self.memory) 25664\n",
      "recent training loss :  67.00935554475791\n",
      "env.sum_rewards:  -25.236999999998037\n",
      "len(self.memory) 25728\n",
      "recent training loss :  71.38628975765887\n",
      "env.sum_rewards:  -25.17299999999796\n",
      "len(self.memory) 25792\n",
      "recent training loss :  63.39943304152291\n",
      "env.sum_rewards:  -25.10899999999788\n",
      "len(self.memory) 25856\n",
      "recent training loss :  70.07101811647527\n",
      "env.sum_rewards:  -25.102999999997873\n",
      "len(self.memory) 25920\n",
      "recent training loss :  61.852731295777815\n",
      "env.sum_rewards:  -25.102999999997873\n",
      "len(self.memory) 25984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recent training loss :  71.52344518291878\n",
      "env.sum_rewards:  -26.039999999997796\n",
      "len(self.memory) 26048\n",
      "recent training loss :  73.0538282784225\n",
      "env.sum_rewards:  -25.97599999999772\n",
      "len(self.memory) 26112\n",
      "recent training loss :  77.19565250707463\n",
      "env.sum_rewards:  -26.91299999999764\n",
      "len(self.memory) 26176\n",
      "recent training loss :  69.93843659866835\n",
      "env.sum_rewards:  -26.916999999997646\n",
      "len(self.memory) 26240\n",
      "recent training loss :  76.4061478317187\n",
      "env.sum_rewards:  -26.852999999997568\n",
      "len(self.memory) 26304\n",
      "recent training loss :  71.51749512849875\n",
      "env.sum_rewards:  -26.78899999999749\n",
      "len(self.memory) 26368\n",
      "recent training loss :  73.33539986102977\n",
      "env.sum_rewards:  -26.72499999999741\n",
      "len(self.memory) 26432\n",
      "recent training loss :  55.17467367922649\n",
      "env.sum_rewards:  -26.660999999997333\n",
      "len(self.memory) 26496\n",
      "recent training loss :  70.98560315391676\n",
      "env.sum_rewards:  -26.596999999997255\n",
      "len(self.memory) 26560\n",
      "recent training loss :  65.33119357993866\n",
      "env.sum_rewards:  -26.532999999997177\n",
      "len(self.memory) 26624\n",
      "recent training loss :  66.80718929061895\n",
      "env.sum_rewards:  -26.4689999999971\n",
      "len(self.memory) 26688\n",
      "recent training loss :  71.44465294904674\n",
      "env.sum_rewards:  -26.40499999999702\n",
      "len(self.memory) 26752\n",
      "recent training loss :  69.84868728578263\n",
      "env.sum_rewards:  -26.340999999996942\n",
      "len(self.memory) 26816\n",
      "recent training loss :  75.62880150209854\n",
      "env.sum_rewards:  -26.276999999996864\n",
      "len(self.memory) 26880\n",
      "recent training loss :  69.04224169078864\n",
      "env.sum_rewards:  -26.212999999996786\n",
      "len(self.memory) 26944\n",
      "recent training loss :  67.61406871386643\n",
      "env.sum_rewards:  -26.148999999996708\n",
      "len(self.memory) 27008\n",
      "recent training loss :  73.34525961150035\n",
      "env.sum_rewards:  -26.08499999999663\n",
      "len(self.memory) 27072\n",
      "recent training loss :  75.73605663141151\n",
      "env.sum_rewards:  -26.02099999999655\n",
      "len(self.memory) 27136\n",
      "recent training loss :  65.63574747344774\n",
      "env.sum_rewards:  -26.016999999996546\n",
      "len(self.memory) 27200\n",
      "recent training loss :  70.04320567944934\n",
      "env.sum_rewards:  -26.01299999999654\n",
      "len(self.memory) 27264\n",
      "recent training loss :  72.92013066306235\n",
      "env.sum_rewards:  -25.948999999996463\n",
      "len(self.memory) 27328\n",
      "recent training loss :  70.03823004733943\n",
      "env.sum_rewards:  -25.96299999999648\n",
      "len(self.memory) 27392\n",
      "recent training loss :  73.28282757586996\n",
      "env.sum_rewards:  -25.898999999996402\n",
      "len(self.memory) 27456\n",
      "recent training loss :  64.25965642643618\n",
      "env.sum_rewards:  -25.834999999996324\n",
      "len(self.memory) 27520\n",
      "recent training loss :  76.50827305985904\n",
      "env.sum_rewards:  -25.770999999996246\n",
      "len(self.memory) 27584\n",
      "recent training loss :  61.906185320425934\n",
      "env.sum_rewards:  -25.706999999996167\n",
      "len(self.memory) 27648\n",
      "recent training loss :  69.83919840748241\n",
      "env.sum_rewards:  -25.70099999999616\n",
      "len(self.memory) 27712\n",
      "recent training loss :  69.02439684502237\n",
      "env.sum_rewards:  -25.698999999996158\n",
      "len(self.memory) 27776\n",
      "recent training loss :  75.26837398665832\n",
      "env.sum_rewards:  -25.706999999996167\n",
      "len(self.memory) 27840\n",
      "recent training loss :  70.52341565393685\n",
      "env.sum_rewards:  -25.64299999999609\n",
      "len(self.memory) 27904\n",
      "recent training loss :  65.85628407262348\n",
      "env.sum_rewards:  -25.57899999999601\n",
      "len(self.memory) 27968\n",
      "recent training loss :  65.56432996397672\n",
      "env.sum_rewards:  -25.514999999995933\n",
      "len(self.memory) 28032\n",
      "recent training loss :  81.16641726650957\n",
      "env.sum_rewards:  -25.450999999995854\n",
      "len(self.memory) 28096\n",
      "recent training loss :  76.99896104959433\n",
      "env.sum_rewards:  -25.386999999995776\n",
      "len(self.memory) 28160\n",
      "recent training loss :  81.1530322082075\n",
      "env.sum_rewards:  -25.376999999995764\n",
      "len(self.memory) 28224\n",
      "recent training loss :  73.47147830333893\n",
      "env.sum_rewards:  -25.312999999995686\n",
      "len(self.memory) 28288\n",
      "recent training loss :  58.98980815285124\n",
      "env.sum_rewards:  -25.326999999995703\n",
      "len(self.memory) 28352\n",
      "recent training loss :  69.49657118753773\n",
      "env.sum_rewards:  -25.34099999999572\n",
      "len(self.memory) 28416\n",
      "recent training loss :  69.39570595170866\n",
      "env.sum_rewards:  -25.334999999995713\n",
      "len(self.memory) 28480\n",
      "recent training loss :  69.64317845927313\n",
      "env.sum_rewards:  -25.334999999995713\n",
      "len(self.memory) 28544\n",
      "recent training loss :  72.46776997247832\n",
      "env.sum_rewards:  -25.270999999995635\n",
      "len(self.memory) 28608\n",
      "recent training loss :  78.7429077369467\n",
      "env.sum_rewards:  -25.206999999995556\n",
      "len(self.memory) 28672\n",
      "recent training loss :  72.84018341536417\n",
      "env.sum_rewards:  -25.142999999995478\n",
      "len(self.memory) 28736\n",
      "recent training loss :  67.26899252737132\n",
      "env.sum_rewards:  -25.0789999999954\n",
      "len(self.memory) 28800\n",
      "recent training loss :  73.09309472054227\n",
      "env.sum_rewards:  -25.01499999999532\n",
      "len(self.memory) 28864\n",
      "recent training loss :  74.31723982946932\n",
      "env.sum_rewards:  -24.952999999995246\n",
      "len(self.memory) 28928\n",
      "recent training loss :  72.21601644725733\n",
      "env.sum_rewards:  -24.888999999995168\n",
      "len(self.memory) 28992\n",
      "recent training loss :  67.18117510471777\n",
      "env.sum_rewards:  -23.885999999995164\n",
      "len(self.memory) 29056\n",
      "recent training loss :  74.29704954598992\n",
      "env.sum_rewards:  -23.821999999995086\n",
      "len(self.memory) 29120\n",
      "recent training loss :  72.92122064065248\n",
      "env.sum_rewards:  -23.80799999999507\n",
      "len(self.memory) 29184\n",
      "recent training loss :  73.5341062284636\n",
      "env.sum_rewards:  -23.74399999999499\n",
      "len(self.memory) 29248\n",
      "recent training loss :  72.21742707717755\n",
      "env.sum_rewards:  -23.679999999994912\n",
      "len(self.memory) 29312\n",
      "recent training loss :  77.71023277302515\n",
      "env.sum_rewards:  -23.615999999994834\n",
      "len(self.memory) 29376\n",
      "recent training loss :  69.05310752693427\n",
      "env.sum_rewards:  -23.615999999994834\n",
      "len(self.memory) 29440\n",
      "recent training loss :  75.00223557776906\n",
      "env.sum_rewards:  -23.551999999994756\n",
      "len(self.memory) 29504\n",
      "recent training loss :  81.14662161763837\n",
      "env.sum_rewards:  -23.487999999994678\n",
      "len(self.memory) 29568\n",
      "recent training loss :  62.5046847859158\n",
      "env.sum_rewards:  -23.4239999999946\n",
      "len(self.memory) 29632\n",
      "recent training loss :  78.42187831867656\n",
      "env.sum_rewards:  -23.35999999999452\n",
      "len(self.memory) 29696\n",
      "recent training loss :  72.13251050131706\n",
      "env.sum_rewards:  -23.295999999994443\n",
      "len(self.memory) 29760\n",
      "recent training loss :  71.06497657381304\n",
      "env.sum_rewards:  -23.231999999994365\n",
      "len(self.memory) 29824\n",
      "recent training loss :  70.38186762719991\n",
      "env.sum_rewards:  -23.167999999994286\n",
      "len(self.memory) 29888\n",
      "recent training loss :  72.3143814281546\n",
      "env.sum_rewards:  -23.10399999999421\n",
      "len(self.memory) 29952\n",
      "recent training loss :  72.55986372489683\n",
      "env.sum_rewards:  -23.03999999999413\n",
      "len(self.memory) 30016\n",
      "recent training loss :  74.83516255507277\n",
      "env.sum_rewards:  -23.03999999999413\n",
      "len(self.memory) 30080\n",
      "recent training loss :  71.43854288795444\n",
      "env.sum_rewards:  -22.975999999994052\n",
      "len(self.memory) 30144\n",
      "recent training loss :  71.03185305348693\n",
      "env.sum_rewards:  -22.911999999993974\n",
      "len(self.memory) 30208\n",
      "recent training loss :  68.63001393436866\n",
      "env.sum_rewards:  -22.91799999999398\n",
      "len(self.memory) 30272\n",
      "recent training loss :  65.73361836356382\n",
      "env.sum_rewards:  -22.853999999993903\n",
      "len(self.memory) 30336\n",
      "recent training loss :  71.13981080287881\n",
      "env.sum_rewards:  -22.789999999993825\n",
      "len(self.memory) 30400\n",
      "recent training loss :  75.42585989882767\n",
      "env.sum_rewards:  -22.799999999993837\n",
      "len(self.memory) 30464\n",
      "recent training loss :  82.77649192152093\n",
      "env.sum_rewards:  -22.799999999993837\n",
      "len(self.memory) 30528\n",
      "recent training loss :  69.40312516541138\n",
      "env.sum_rewards:  -22.73599999999376\n",
      "len(self.memory) 30592\n",
      "recent training loss :  64.8677192381357\n",
      "env.sum_rewards:  -22.67199999999368\n",
      "len(self.memory) 30656\n",
      "recent training loss :  76.69218548962183\n",
      "env.sum_rewards:  -22.659999999993666\n",
      "len(self.memory) 30720\n",
      "recent training loss :  68.62992889284307\n",
      "env.sum_rewards:  -22.595999999993587\n",
      "len(self.memory) 30784\n",
      "recent training loss :  70.62598684746277\n",
      "env.sum_rewards:  -22.53199999999351\n",
      "len(self.memory) 30848\n",
      "recent training loss :  69.41235038082043\n",
      "env.sum_rewards:  -22.46799999999343\n",
      "len(self.memory) 30912\n",
      "recent training loss :  70.40704463921887\n",
      "env.sum_rewards:  -22.403999999993353\n",
      "len(self.memory) 30976\n",
      "recent training loss :  72.15903372519297\n",
      "env.sum_rewards:  -22.339999999993275\n",
      "len(self.memory) 31040\n",
      "recent training loss :  79.48714199431774\n",
      "env.sum_rewards:  -22.275999999993196\n",
      "len(self.memory) 31104\n",
      "recent training loss :  77.94116545836941\n",
      "env.sum_rewards:  -22.211999999993118\n",
      "len(self.memory) 31168\n",
      "recent training loss :  72.93244982926069\n",
      "env.sum_rewards:  -22.14799999999304\n",
      "len(self.memory) 31232\n",
      "recent training loss :  71.02498297477123\n",
      "env.sum_rewards:  -22.08399999999296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(self.memory) 31296\n",
      "recent training loss :  69.17861136037233\n",
      "env.sum_rewards:  -22.08999999999297\n",
      "len(self.memory) 31360\n",
      "recent training loss :  66.58543055771173\n",
      "env.sum_rewards:  -22.02599999999289\n",
      "len(self.memory) 31424\n",
      "recent training loss :  72.0413244337714\n",
      "env.sum_rewards:  -21.961999999992813\n",
      "len(self.memory) 31488\n",
      "recent training loss :  68.98724776608918\n",
      "env.sum_rewards:  -21.955999999992805\n",
      "len(self.memory) 31552\n",
      "recent training loss :  64.96307033592595\n",
      "env.sum_rewards:  -21.891999999992727\n",
      "len(self.memory) 31616\n",
      "recent training loss :  69.165497690302\n",
      "env.sum_rewards:  -22.82899999999265\n",
      "len(self.memory) 31680\n",
      "recent training loss :  77.07535584827755\n",
      "env.sum_rewards:  -22.764999999992572\n",
      "len(self.memory) 31744\n",
      "recent training loss :  61.84733985715944\n",
      "env.sum_rewards:  -22.700999999992494\n",
      "len(self.memory) 31808\n",
      "recent training loss :  73.55791147496751\n",
      "env.sum_rewards:  -22.636999999992415\n",
      "len(self.memory) 31872\n",
      "recent training loss :  73.73400304439457\n",
      "env.sum_rewards:  -22.572999999992337\n",
      "len(self.memory) 31936\n",
      "recent training loss :  71.80074742813937\n",
      "env.sum_rewards:  -22.50899999999226\n",
      "len(self.memory) 32000\n",
      "recent training loss :  73.23051293680828\n",
      "env.sum_rewards:  -22.50299999999225\n",
      "len(self.memory) 32064\n",
      "recent training loss :  67.17310753491492\n",
      "env.sum_rewards:  -23.439999999992175\n",
      "len(self.memory) 32128\n",
      "recent training loss :  73.29174331529951\n",
      "max_t exceeded:  501\n",
      "==========================EPOCH 1 COMPLETED===================\n",
      "Current state :  1\n",
      "env.sum_rewards:  -23.375999999992096\n",
      "len(self.memory) 32192\n",
      "recent training loss :  57.49871067719707\n",
      "env.sum_rewards:  -23.311999999992018\n",
      "len(self.memory) 32256\n",
      "recent training loss :  77.4730602744578\n",
      "env.sum_rewards:  -23.24799999999194\n",
      "len(self.memory) 32320\n",
      "recent training loss :  72.13334880830715\n",
      "env.sum_rewards:  -23.183999999991862\n",
      "len(self.memory) 32384\n",
      "recent training loss :  78.02003865745921\n",
      "env.sum_rewards:  -23.119999999991784\n",
      "len(self.memory) 32448\n",
      "recent training loss :  74.69099194565806\n",
      "env.sum_rewards:  -23.055999999991705\n",
      "len(self.memory) 32512\n",
      "recent training loss :  76.25159395526066\n",
      "env.sum_rewards:  -22.054999999991704\n",
      "len(self.memory) 32576\n",
      "recent training loss :  68.55416018866576\n",
      "env.sum_rewards:  -21.990999999991626\n",
      "len(self.memory) 32640\n",
      "recent training loss :  72.49225461795228\n",
      "env.sum_rewards:  -21.98699999999162\n",
      "len(self.memory) 32704\n",
      "recent training loss :  63.40539297925726\n",
      "env.sum_rewards:  -21.922999999991543\n",
      "len(self.memory) 32768\n",
      "recent training loss :  76.15924124567496\n",
      "env.sum_rewards:  -21.858999999991465\n",
      "len(self.memory) 32832\n",
      "recent training loss :  75.40311110718753\n",
      "env.sum_rewards:  -21.794999999991386\n",
      "len(self.memory) 32896\n",
      "recent training loss :  69.91293635400581\n",
      "env.sum_rewards:  -21.79899999999139\n",
      "len(self.memory) 32960\n",
      "recent training loss :  73.61275390589627\n",
      "env.sum_rewards:  -21.734999999991313\n",
      "len(self.memory) 33024\n",
      "recent training loss :  67.25328789839688\n",
      "env.sum_rewards:  -21.734999999991313\n",
      "len(self.memory) 33088\n",
      "recent training loss :  74.3657178216989\n",
      "env.sum_rewards:  -21.670999999991235\n",
      "len(self.memory) 33152\n",
      "recent training loss :  72.21628667812475\n",
      "env.sum_rewards:  -22.669999999991234\n",
      "len(self.memory) 33216\n",
      "recent training loss :  61.565719811589545\n",
      "env.sum_rewards:  -22.66799999999123\n",
      "len(self.memory) 33280\n",
      "recent training loss :  71.54131038924238\n",
      "env.sum_rewards:  -22.67599999999124\n",
      "len(self.memory) 33344\n",
      "recent training loss :  71.73724430092682\n",
      "env.sum_rewards:  -22.611999999991163\n",
      "len(self.memory) 33408\n",
      "recent training loss :  77.7319794983398\n",
      "env.sum_rewards:  -23.60099999999115\n",
      "len(self.memory) 33472\n",
      "recent training loss :  79.49412711201828\n",
      "env.sum_rewards:  -23.53699999999107\n",
      "len(self.memory) 33536\n",
      "recent training loss :  66.9406880783952\n",
      "env.sum_rewards:  -23.472999999990993\n",
      "len(self.memory) 33600\n",
      "recent training loss :  72.52649630909292\n",
      "env.sum_rewards:  -23.408999999990915\n",
      "len(self.memory) 33664\n",
      "recent training loss :  72.37337664991203\n",
      "env.sum_rewards:  -24.345999999990838\n",
      "len(self.memory) 33728\n",
      "recent training loss :  74.34442459008415\n",
      "env.sum_rewards:  -24.28199999999076\n",
      "len(self.memory) 33792\n",
      "recent training loss :  68.60964358380927\n",
      "env.sum_rewards:  -24.21799999999068\n",
      "len(self.memory) 33856\n",
      "recent training loss :  68.81767156389577\n",
      "env.sum_rewards:  -25.154999999990604\n",
      "len(self.memory) 33920\n",
      "recent training loss :  71.96684759159609\n",
      "env.sum_rewards:  -26.091999999990527\n",
      "len(self.memory) 33984\n",
      "recent training loss :  78.22870838018338\n",
      "env.sum_rewards:  -26.02799999999045\n",
      "len(self.memory) 34048\n",
      "recent training loss :  72.21876324181669\n",
      "env.sum_rewards:  -25.96399999999037\n",
      "len(self.memory) 34112\n",
      "recent training loss :  78.81939240624774\n",
      "env.sum_rewards:  -25.899999999990293\n",
      "len(self.memory) 34176\n",
      "recent training loss :  62.039698839820744\n",
      "env.sum_rewards:  -25.907999999990302\n",
      "len(self.memory) 34240\n",
      "recent training loss :  72.584047743989\n",
      "env.sum_rewards:  -25.895999999990288\n",
      "len(self.memory) 34304\n",
      "recent training loss :  58.43161854678965\n",
      "env.sum_rewards:  -25.83199999999021\n",
      "len(self.memory) 34368\n",
      "recent training loss :  67.77047617984812\n",
      "env.sum_rewards:  -25.825999999990202\n",
      "len(self.memory) 34432\n",
      "recent training loss :  69.3893565225953\n",
      "env.sum_rewards:  -26.762999999990125\n",
      "len(self.memory) 34496\n",
      "recent training loss :  72.41988872897588\n",
      "env.sum_rewards:  -26.698999999990047\n",
      "len(self.memory) 34560\n",
      "recent training loss :  69.18910714422086\n",
      "env.sum_rewards:  -26.63499999998997\n",
      "len(self.memory) 34624\n",
      "recent training loss :  66.72312500635167\n",
      "env.sum_rewards:  -26.57099999998989\n",
      "len(self.memory) 34688\n",
      "recent training loss :  61.149865442340925\n",
      "env.sum_rewards:  -26.576999999989898\n",
      "len(self.memory) 34752\n",
      "recent training loss :  72.46325811785232\n",
      "env.sum_rewards:  -26.51299999998982\n",
      "len(self.memory) 34816\n",
      "recent training loss :  73.77614841058897\n",
      "env.sum_rewards:  -26.44899999998974\n",
      "len(self.memory) 34880\n",
      "recent training loss :  79.06418642508683\n",
      "env.sum_rewards:  -26.444999999989736\n",
      "len(self.memory) 34944\n",
      "recent training loss :  77.90153738841047\n",
      "env.sum_rewards:  -26.432999999989722\n",
      "len(self.memory) 35008\n",
      "recent training loss :  73.51709375639652\n",
      "env.sum_rewards:  -26.368999999989644\n",
      "len(self.memory) 35072\n",
      "recent training loss :  72.12540566424109\n",
      "env.sum_rewards:  -26.304999999989565\n",
      "len(self.memory) 35136\n",
      "recent training loss :  77.6538265540986\n",
      "env.sum_rewards:  -26.30899999998957\n",
      "len(self.memory) 35200\n",
      "recent training loss :  76.63689999236486\n",
      "env.sum_rewards:  -26.244999999989492\n",
      "len(self.memory) 35264\n",
      "recent training loss :  71.42995152787174\n",
      "env.sum_rewards:  -26.180999999989414\n",
      "len(self.memory) 35328\n",
      "recent training loss :  67.8408206234626\n",
      "env.sum_rewards:  -26.116999999989336\n",
      "len(self.memory) 35392\n",
      "recent training loss :  67.90731431876054\n",
      "env.sum_rewards:  -26.11099999998933\n",
      "len(self.memory) 35456\n",
      "recent training loss :  69.14996904222323\n",
      "env.sum_rewards:  -26.04699999998925\n",
      "len(self.memory) 35520\n",
      "recent training loss :  70.35689894707339\n",
      "env.sum_rewards:  -25.982999999989172\n",
      "len(self.memory) 35584\n",
      "recent training loss :  82.75011958839545\n",
      "env.sum_rewards:  -25.918999999989094\n",
      "len(self.memory) 35648\n",
      "recent training loss :  69.85541078831784\n",
      "env.sum_rewards:  -25.854999999989015\n",
      "len(self.memory) 35712\n",
      "recent training loss :  73.75437942244493\n",
      "env.sum_rewards:  -25.790999999988937\n",
      "len(self.memory) 35776\n",
      "recent training loss :  64.39308593931831\n",
      "env.sum_rewards:  -25.788999999988935\n",
      "len(self.memory) 35840\n",
      "recent training loss :  67.35203102545157\n",
      "env.sum_rewards:  -25.77699999998892\n",
      "len(self.memory) 35904\n",
      "recent training loss :  78.99477887572459\n",
      "env.sum_rewards:  -25.712999999988842\n",
      "len(self.memory) 35968\n",
      "recent training loss :  74.51263480989834\n",
      "env.sum_rewards:  -25.648999999988764\n",
      "len(self.memory) 36032\n",
      "recent training loss :  62.06403440258555\n",
      "env.sum_rewards:  -25.584999999988685\n",
      "len(self.memory) 36096\n",
      "recent training loss :  65.78015714244803\n",
      "env.sum_rewards:  -25.578999999988678\n",
      "len(self.memory) 36160\n",
      "recent training loss :  68.87449685690548\n",
      "env.sum_rewards:  -25.5149999999886\n",
      "len(self.memory) 36224\n",
      "recent training loss :  72.77082202979659\n",
      "env.sum_rewards:  -25.45099999998852\n",
      "len(self.memory) 36288\n",
      "recent training loss :  68.4410931971834\n",
      "env.sum_rewards:  -25.386999999988443\n",
      "len(self.memory) 36352\n",
      "recent training loss :  74.54780599946797\n",
      "env.sum_rewards:  -25.322999999988365\n",
      "len(self.memory) 36416\n",
      "recent training loss :  73.0577712764702\n",
      "env.sum_rewards:  -25.258999999988287\n",
      "len(self.memory) 36480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recent training loss :  63.01308582845877\n",
      "env.sum_rewards:  -25.19499999998821\n",
      "len(self.memory) 36544\n",
      "recent training loss :  71.42374130211084\n",
      "env.sum_rewards:  -25.13099999998813\n",
      "len(self.memory) 36608\n",
      "recent training loss :  73.91146045689568\n",
      "env.sum_rewards:  -25.066999999988052\n",
      "len(self.memory) 36672\n",
      "recent training loss :  70.00983448673084\n",
      "env.sum_rewards:  -25.002999999987974\n",
      "len(self.memory) 36736\n",
      "recent training loss :  68.26789542993372\n",
      "env.sum_rewards:  -24.938999999987896\n",
      "len(self.memory) 36800\n",
      "recent training loss :  59.22225357038417\n",
      "env.sum_rewards:  -24.874999999987818\n",
      "len(self.memory) 36864\n",
      "recent training loss :  66.70272416372748\n",
      "env.sum_rewards:  -24.81099999998774\n",
      "len(self.memory) 36928\n",
      "recent training loss :  63.710584414155925\n",
      "env.sum_rewards:  -24.74699999998766\n",
      "len(self.memory) 36992\n",
      "recent training loss :  67.37908311930833\n",
      "env.sum_rewards:  -24.682999999987583\n",
      "len(self.memory) 37056\n",
      "recent training loss :  69.40692863758215\n",
      "env.sum_rewards:  -24.618999999987505\n",
      "len(self.memory) 37120\n",
      "recent training loss :  76.97826919316138\n",
      "env.sum_rewards:  -24.554999999987427\n",
      "len(self.memory) 37184\n",
      "recent training loss :  70.40933085838492\n",
      "env.sum_rewards:  -24.49099999998735\n",
      "len(self.memory) 37248\n",
      "recent training loss :  63.411629662256416\n",
      "env.sum_rewards:  -24.494999999987353\n",
      "len(self.memory) 37312\n",
      "recent training loss :  64.96835016523933\n",
      "env.sum_rewards:  -24.494999999987353\n",
      "len(self.memory) 37376\n",
      "recent training loss :  61.25338987668116\n",
      "env.sum_rewards:  -24.430999999987275\n",
      "len(self.memory) 37440\n",
      "recent training loss :  60.388281815972576\n",
      "env.sum_rewards:  -24.42699999998727\n",
      "len(self.memory) 37504\n",
      "recent training loss :  68.06266731482867\n",
      "env.sum_rewards:  -24.362999999987192\n",
      "len(self.memory) 37568\n",
      "recent training loss :  77.88028953923896\n",
      "env.sum_rewards:  -24.3689999999872\n",
      "len(self.memory) 37632\n",
      "recent training loss :  67.9057766222621\n",
      "env.sum_rewards:  -24.30499999998712\n",
      "len(self.memory) 37696\n",
      "recent training loss :  68.19360166400436\n",
      "env.sum_rewards:  -24.240999999987043\n",
      "len(self.memory) 37760\n",
      "recent training loss :  78.60608383633468\n",
      "env.sum_rewards:  -24.176999999986965\n",
      "len(self.memory) 37824\n",
      "recent training loss :  68.87465574241807\n",
      "env.sum_rewards:  -24.112999999986886\n",
      "len(self.memory) 37888\n",
      "recent training loss :  71.85858385157984\n",
      "env.sum_rewards:  -24.04899999998681\n",
      "len(self.memory) 37952\n",
      "recent training loss :  69.48462558308479\n",
      "env.sum_rewards:  -23.98499999998673\n",
      "len(self.memory) 38016\n",
      "recent training loss :  72.44550323322562\n",
      "env.sum_rewards:  -23.920999999986652\n",
      "len(self.memory) 38080\n",
      "recent training loss :  61.50517977518709\n",
      "env.sum_rewards:  -23.856999999986574\n",
      "len(self.memory) 38144\n",
      "recent training loss :  67.19759897203615\n",
      "env.sum_rewards:  -23.792999999986495\n",
      "len(self.memory) 38208\n",
      "recent training loss :  73.48018906298815\n",
      "env.sum_rewards:  -23.728999999986417\n",
      "len(self.memory) 38272\n",
      "recent training loss :  68.34340374401785\n",
      "env.sum_rewards:  -23.66499999998634\n",
      "len(self.memory) 38336\n",
      "recent training loss :  73.76877993148425\n",
      "env.sum_rewards:  -23.60099999998626\n",
      "len(self.memory) 38400\n",
      "recent training loss :  65.74535418896143\n",
      "env.sum_rewards:  -23.536999999986183\n",
      "len(self.memory) 38464\n",
      "recent training loss :  62.190792093220665\n",
      "env.sum_rewards:  -23.472999999986104\n",
      "len(self.memory) 38528\n",
      "recent training loss :  70.92014243602176\n",
      "env.sum_rewards:  -23.466999999986097\n",
      "len(self.memory) 38592\n",
      "recent training loss :  68.6675418116794\n",
      "env.sum_rewards:  -23.442999999986068\n",
      "len(self.memory) 38656\n",
      "recent training loss :  65.43839418538984\n",
      "env.sum_rewards:  -23.37899999998599\n",
      "len(self.memory) 38720\n",
      "recent training loss :  67.17971780162065\n",
      "env.sum_rewards:  -23.31499999998591\n",
      "len(self.memory) 38784\n",
      "recent training loss :  62.81967593678374\n",
      "env.sum_rewards:  -23.250999999985833\n",
      "len(self.memory) 38848\n",
      "recent training loss :  69.53346908736137\n",
      "env.sum_rewards:  -23.186999999985755\n",
      "len(self.memory) 38912\n",
      "recent training loss :  69.12383335824916\n",
      "env.sum_rewards:  -23.122999999985677\n",
      "len(self.memory) 38976\n",
      "recent training loss :  69.04366066058935\n",
      "env.sum_rewards:  -24.0599999999856\n",
      "len(self.memory) 39040\n",
      "recent training loss :  77.78097612620812\n",
      "env.sum_rewards:  -23.99599999998552\n",
      "len(self.memory) 39104\n",
      "recent training loss :  62.30762533114123\n",
      "env.sum_rewards:  -23.931999999985443\n",
      "len(self.memory) 39168\n",
      "recent training loss :  75.44275348764702\n",
      "env.sum_rewards:  -23.867999999985365\n",
      "len(self.memory) 39232\n",
      "recent training loss :  67.74783001644126\n",
      "env.sum_rewards:  -23.803999999985287\n",
      "len(self.memory) 39296\n",
      "recent training loss :  66.04858635720073\n",
      "env.sum_rewards:  -23.73999999998521\n",
      "len(self.memory) 39360\n",
      "recent training loss :  74.71341454408184\n",
      "env.sum_rewards:  -23.67599999998513\n",
      "len(self.memory) 39424\n",
      "recent training loss :  72.8368123545159\n",
      "env.sum_rewards:  -23.611999999985052\n",
      "len(self.memory) 39488\n",
      "recent training loss :  72.81112424040347\n",
      "env.sum_rewards:  -23.547999999984974\n",
      "len(self.memory) 39552\n",
      "recent training loss :  68.67820604478258\n",
      "env.sum_rewards:  -23.483999999984896\n",
      "len(self.memory) 39616\n",
      "recent training loss :  67.74885592604952\n",
      "env.sum_rewards:  -23.419999999984817\n",
      "len(self.memory) 39680\n",
      "recent training loss :  79.6235969188572\n",
      "env.sum_rewards:  -23.35599999998474\n",
      "len(self.memory) 39744\n",
      "recent training loss :  74.8000713504411\n",
      "env.sum_rewards:  -23.29199999998466\n",
      "len(self.memory) 39808\n",
      "recent training loss :  79.32727845570363\n",
      "env.sum_rewards:  -23.227999999984583\n",
      "len(self.memory) 39872\n",
      "recent training loss :  73.53167253773677\n",
      "env.sum_rewards:  -23.163999999984505\n",
      "len(self.memory) 39936\n",
      "recent training loss :  72.21828586892283\n",
      "env.sum_rewards:  -23.099999999984426\n",
      "len(self.memory) 40000\n",
      "recent training loss :  66.57357759076234\n",
      "env.sum_rewards:  -23.09399999998442\n",
      "len(self.memory) 40064\n",
      "recent training loss :  78.07334652644859\n",
      "env.sum_rewards:  -23.09599999998442\n",
      "len(self.memory) 40128\n",
      "recent training loss :  67.75640242910455\n",
      "env.sum_rewards:  -23.10399999998443\n",
      "len(self.memory) 40192\n",
      "recent training loss :  54.21008992368201\n",
      "env.sum_rewards:  -23.039999999984353\n",
      "len(self.memory) 40256\n",
      "recent training loss :  73.73952890508733\n",
      "env.sum_rewards:  -22.975999999984275\n",
      "len(self.memory) 40320\n",
      "recent training loss :  74.35597525583674\n",
      "env.sum_rewards:  -22.911999999984197\n",
      "len(self.memory) 40384\n",
      "recent training loss :  64.49132898465623\n",
      "env.sum_rewards:  -22.84799999998412\n",
      "len(self.memory) 40448\n",
      "recent training loss :  70.80588702960054\n",
      "env.sum_rewards:  -22.78399999998404\n",
      "len(self.memory) 40512\n",
      "recent training loss :  72.1809327533576\n",
      "env.sum_rewards:  -22.719999999983962\n",
      "len(self.memory) 40576\n",
      "recent training loss :  71.47019912561504\n",
      "env.sum_rewards:  -22.655999999983884\n",
      "len(self.memory) 40640\n",
      "recent training loss :  63.22164982024688\n",
      "env.sum_rewards:  -22.591999999983805\n",
      "len(self.memory) 40704\n",
      "recent training loss :  75.04843285845087\n",
      "env.sum_rewards:  -22.5879999999838\n",
      "len(self.memory) 40768\n",
      "recent training loss :  68.30896997259528\n",
      "env.sum_rewards:  -22.523999999983722\n",
      "len(self.memory) 40832\n",
      "recent training loss :  67.8470911796424\n",
      "env.sum_rewards:  -22.459999999983644\n",
      "len(self.memory) 40896\n",
      "recent training loss :  62.54813311523331\n",
      "env.sum_rewards:  -22.395999999983566\n",
      "len(self.memory) 40960\n",
      "recent training loss :  71.17453566202522\n",
      "env.sum_rewards:  -22.39799999998357\n",
      "len(self.memory) 41024\n",
      "recent training loss :  62.443576433865985\n",
      "env.sum_rewards:  -22.33399999998349\n",
      "len(self.memory) 41088\n",
      "recent training loss :  70.37263139435484\n",
      "env.sum_rewards:  -22.269999999983412\n",
      "len(self.memory) 41152\n",
      "recent training loss :  68.36753596883989\n",
      "env.sum_rewards:  -22.205999999983334\n",
      "len(self.memory) 41216\n",
      "recent training loss :  69.86043689302082\n",
      "env.sum_rewards:  -22.141999999983256\n",
      "len(self.memory) 41280\n",
      "recent training loss :  70.38571912608809\n",
      "env.sum_rewards:  -22.077999999983177\n",
      "len(self.memory) 41344\n",
      "recent training loss :  69.719863654986\n",
      "env.sum_rewards:  -22.0139999999831\n",
      "len(self.memory) 41408\n",
      "recent training loss :  72.6236096378243\n",
      "env.sum_rewards:  -21.94999999998302\n",
      "len(self.memory) 41472\n",
      "recent training loss :  73.97973957275619\n",
      "env.sum_rewards:  -21.94999999998302\n",
      "len(self.memory) 41536\n",
      "recent training loss :  70.58037287037948\n",
      "env.sum_rewards:  -21.885999999982943\n",
      "len(self.memory) 41600\n",
      "recent training loss :  70.70451229388344\n",
      "env.sum_rewards:  -21.821999999982864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(self.memory) 41664\n",
      "recent training loss :  73.96856369117408\n",
      "env.sum_rewards:  -21.80999999998285\n",
      "len(self.memory) 41728\n",
      "recent training loss :  74.81669525470957\n",
      "env.sum_rewards:  -21.74599999998277\n",
      "len(self.memory) 41792\n",
      "recent training loss :  69.2012642758207\n",
      "env.sum_rewards:  -21.681999999982693\n",
      "len(self.memory) 41856\n",
      "recent training loss :  69.34479614184679\n",
      "env.sum_rewards:  -21.617999999982615\n",
      "len(self.memory) 41920\n",
      "recent training loss :  64.76421490673428\n",
      "env.sum_rewards:  -21.553999999982537\n",
      "len(self.memory) 41984\n",
      "recent training loss :  73.67118430361958\n",
      "env.sum_rewards:  -21.48999999998246\n",
      "len(self.memory) 42048\n",
      "recent training loss :  75.67393834876921\n",
      "env.sum_rewards:  -21.50599999998248\n",
      "len(self.memory) 42112\n",
      "recent training loss :  63.2431356998616\n",
      "env.sum_rewards:  -21.4419999999824\n",
      "len(self.memory) 42176\n",
      "recent training loss :  76.80373564473263\n",
      "env.sum_rewards:  -21.377999999982322\n",
      "len(self.memory) 42240\n",
      "recent training loss :  66.32465236308292\n",
      "env.sum_rewards:  -21.313999999982244\n",
      "len(self.memory) 42304\n",
      "recent training loss :  67.03718578624623\n",
      "env.sum_rewards:  -21.249999999982165\n",
      "len(self.memory) 42368\n",
      "recent training loss :  71.2271849056759\n",
      "env.sum_rewards:  -21.247999999982163\n",
      "len(self.memory) 42432\n",
      "recent training loss :  73.69019650874262\n",
      "env.sum_rewards:  -21.183999999982085\n",
      "len(self.memory) 42496\n",
      "recent training loss :  68.51015609702824\n",
      "env.sum_rewards:  -21.119999999982006\n",
      "len(self.memory) 42560\n",
      "recent training loss :  64.52238062624053\n",
      "env.sum_rewards:  -21.05599999998193\n",
      "len(self.memory) 42624\n",
      "recent training loss :  63.82484509298502\n",
      "env.sum_rewards:  -20.99199999998185\n",
      "len(self.memory) 42688\n",
      "recent training loss :  54.56121293024185\n",
      "env.sum_rewards:  -20.927999999981772\n",
      "len(self.memory) 42752\n",
      "recent training loss :  67.0265270931534\n",
      "env.sum_rewards:  -20.863999999981694\n",
      "len(self.memory) 42816\n",
      "recent training loss :  70.54459602646959\n",
      "env.sum_rewards:  -20.799999999981615\n",
      "len(self.memory) 42880\n",
      "recent training loss :  73.94186983730533\n",
      "env.sum_rewards:  -20.735999999981537\n",
      "len(self.memory) 42944\n",
      "recent training loss :  75.23791709294511\n",
      "env.sum_rewards:  -20.67199999998146\n",
      "len(self.memory) 43008\n",
      "recent training loss :  72.33813547738262\n",
      "env.sum_rewards:  -20.669999999981457\n",
      "len(self.memory) 43072\n",
      "recent training loss :  78.34323252613487\n",
      "env.sum_rewards:  -20.67999999998147\n",
      "len(self.memory) 43136\n",
      "recent training loss :  66.7898835673074\n",
      "env.sum_rewards:  -21.618999999981394\n",
      "len(self.memory) 43200\n",
      "recent training loss :  72.21934719590988\n",
      "env.sum_rewards:  -21.554999999981316\n",
      "len(self.memory) 43264\n",
      "recent training loss :  65.04968610578511\n",
      "env.sum_rewards:  -21.490999999981238\n",
      "len(self.memory) 43328\n",
      "recent training loss :  72.14657877221632\n",
      "env.sum_rewards:  -21.42699999998116\n",
      "len(self.memory) 43392\n",
      "recent training loss :  74.12249378922313\n",
      "env.sum_rewards:  -21.36299999998108\n",
      "len(self.memory) 43456\n",
      "recent training loss :  69.53584707893052\n",
      "env.sum_rewards:  -21.298999999981003\n",
      "len(self.memory) 43520\n",
      "recent training loss :  65.9493640719854\n",
      "env.sum_rewards:  -21.234999999980925\n",
      "len(self.memory) 43584\n",
      "recent training loss :  69.12224933628895\n",
      "env.sum_rewards:  -21.170999999980847\n",
      "len(self.memory) 43648\n",
      "recent training loss :  72.1600682417164\n",
      "env.sum_rewards:  -21.168999999980844\n",
      "len(self.memory) 43712\n",
      "recent training loss :  72.04426853615385\n",
      "env.sum_rewards:  -21.104999999980766\n",
      "len(self.memory) 43776\n",
      "recent training loss :  79.88849748715634\n",
      "env.sum_rewards:  -21.040999999980688\n",
      "len(self.memory) 43840\n",
      "recent training loss :  77.14572234823741\n",
      "env.sum_rewards:  -20.97699999998061\n",
      "len(self.memory) 43904\n",
      "recent training loss :  76.01067550859082\n",
      "env.sum_rewards:  -20.91299999998053\n",
      "len(self.memory) 43968\n",
      "recent training loss :  72.73303953148283\n",
      "env.sum_rewards:  -20.91299999998053\n",
      "len(self.memory) 44032\n",
      "recent training loss :  71.42741680676936\n",
      "env.sum_rewards:  -20.848999999980453\n",
      "len(self.memory) 44096\n",
      "recent training loss :  78.75176959659377\n",
      "env.sum_rewards:  -20.83099999998043\n",
      "len(self.memory) 44160\n",
      "recent training loss :  69.30156371956241\n",
      "env.sum_rewards:  -20.766999999980353\n",
      "len(self.memory) 44224\n",
      "recent training loss :  61.326971044088324\n",
      "env.sum_rewards:  -20.702999999980275\n",
      "len(self.memory) 44288\n",
      "recent training loss :  69.15447911489329\n",
      "env.sum_rewards:  -20.69899999998027\n",
      "len(self.memory) 44352\n",
      "recent training loss :  76.8882232060435\n",
      "env.sum_rewards:  -20.63499999998019\n",
      "len(self.memory) 44416\n",
      "recent training loss :  67.50326547804816\n",
      "env.sum_rewards:  -20.570999999980113\n",
      "len(self.memory) 44480\n",
      "recent training loss :  64.67121892345709\n",
      "env.sum_rewards:  -20.506999999980035\n",
      "len(self.memory) 44544\n",
      "recent training loss :  67.61526246138273\n",
      "env.sum_rewards:  -20.442999999979957\n",
      "len(self.memory) 44608\n",
      "recent training loss :  65.33418511476631\n",
      "env.sum_rewards:  -20.37899999997988\n",
      "len(self.memory) 44672\n",
      "recent training loss :  70.81747501812161\n",
      "env.sum_rewards:  -20.3149999999798\n",
      "len(self.memory) 44736\n",
      "recent training loss :  80.91870190488005\n",
      "env.sum_rewards:  -20.250999999979722\n",
      "len(self.memory) 44800\n",
      "recent training loss :  67.89823111693616\n",
      "env.sum_rewards:  -20.260999999979735\n",
      "len(self.memory) 44864\n",
      "recent training loss :  77.02664630421677\n",
      "env.sum_rewards:  -20.244999999979715\n",
      "len(self.memory) 44928\n",
      "recent training loss :  70.02505045226874\n",
      "env.sum_rewards:  -20.180999999979637\n",
      "len(self.memory) 44992\n",
      "recent training loss :  73.81241283977343\n",
      "env.sum_rewards:  -21.11799999997956\n",
      "len(self.memory) 45056\n",
      "recent training loss :  67.73710865759054\n",
      "env.sum_rewards:  -22.054999999979483\n",
      "len(self.memory) 45120\n",
      "recent training loss :  69.53723120916277\n",
      "env.sum_rewards:  -21.990999999979405\n",
      "len(self.memory) 45184\n",
      "recent training loss :  72.98051798401728\n",
      "env.sum_rewards:  -21.926999999979326\n",
      "len(self.memory) 45248\n",
      "recent training loss :  67.92530190435549\n",
      "env.sum_rewards:  -21.862999999979248\n",
      "len(self.memory) 45312\n",
      "recent training loss :  69.08771968158752\n",
      "env.sum_rewards:  -21.79899999997917\n",
      "len(self.memory) 45376\n",
      "recent training loss :  72.66999549142872\n",
      "env.sum_rewards:  -21.73499999997909\n",
      "len(self.memory) 45440\n",
      "recent training loss :  69.11575728086727\n",
      "env.sum_rewards:  -21.720999999979075\n",
      "len(self.memory) 45504\n",
      "recent training loss :  56.2360984095012\n",
      "env.sum_rewards:  -21.656999999978996\n",
      "len(self.memory) 45568\n",
      "recent training loss :  68.54402183764991\n",
      "env.sum_rewards:  -21.592999999978918\n",
      "len(self.memory) 45632\n",
      "recent training loss :  64.56323414183092\n",
      "env.sum_rewards:  -21.52899999997884\n",
      "len(self.memory) 45696\n",
      "recent training loss :  50.77923511052033\n",
      "env.sum_rewards:  -21.46499999997876\n",
      "len(self.memory) 45760\n",
      "recent training loss :  64.13107067049025\n",
      "env.sum_rewards:  -21.400999999978684\n",
      "len(self.memory) 45824\n",
      "recent training loss :  76.31097100866282\n",
      "env.sum_rewards:  -21.336999999978605\n",
      "len(self.memory) 45888\n",
      "recent training loss :  66.05223700865679\n",
      "env.sum_rewards:  -21.272999999978527\n",
      "len(self.memory) 45952\n",
      "recent training loss :  65.7269400743973\n",
      "env.sum_rewards:  -21.20899999997845\n",
      "len(self.memory) 46016\n",
      "recent training loss :  58.38766006001635\n",
      "env.sum_rewards:  -21.21899999997846\n",
      "len(self.memory) 46080\n",
      "recent training loss :  68.35802249782125\n",
      "env.sum_rewards:  -21.154999999978383\n",
      "len(self.memory) 46144\n",
      "recent training loss :  71.67428128461603\n",
      "env.sum_rewards:  -21.090999999978305\n",
      "len(self.memory) 46208\n",
      "recent training loss :  70.14273996555907\n",
      "env.sum_rewards:  -21.026999999978226\n",
      "len(self.memory) 46272\n",
      "recent training loss :  81.32616720044729\n",
      "env.sum_rewards:  -20.96299999997815\n",
      "len(self.memory) 46336\n",
      "recent training loss :  73.93964332622701\n",
      "env.sum_rewards:  -20.89899999997807\n",
      "len(self.memory) 46400\n",
      "recent training loss :  69.37513456551187\n",
      "env.sum_rewards:  -20.834999999977992\n",
      "len(self.memory) 46464\n",
      "recent training loss :  67.11353440723488\n",
      "env.sum_rewards:  -20.770999999977914\n",
      "len(self.memory) 46528\n",
      "recent training loss :  63.0737752830355\n",
      "env.sum_rewards:  -20.77699999997792\n",
      "len(self.memory) 46592\n",
      "recent training loss :  81.41074840542234\n",
      "env.sum_rewards:  -21.713999999977844\n",
      "len(self.memory) 46656\n",
      "recent training loss :  70.62772113952524\n",
      "env.sum_rewards:  -20.706999999977835\n",
      "len(self.memory) 46720\n",
      "recent training loss :  72.94461145920053\n",
      "env.sum_rewards:  -20.642999999977757\n",
      "len(self.memory) 46784\n",
      "recent training loss :  72.31564157706924\n",
      "env.sum_rewards:  -20.57899999997768\n",
      "len(self.memory) 46848\n",
      "recent training loss :  63.006867493020046\n",
      "env.sum_rewards:  -20.582999999977684\n",
      "len(self.memory) 46912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recent training loss :  69.06109584969212\n",
      "env.sum_rewards:  -20.518999999977606\n",
      "len(self.memory) 46976\n",
      "recent training loss :  70.78818241227137\n",
      "env.sum_rewards:  -20.454999999977527\n",
      "len(self.memory) 47040\n",
      "recent training loss :  67.35298050646213\n",
      "env.sum_rewards:  -20.39099999997745\n",
      "len(self.memory) 47104\n",
      "recent training loss :  74.34766372350413\n",
      "env.sum_rewards:  -20.32699999997737\n",
      "len(self.memory) 47168\n",
      "recent training loss :  75.62007636859022\n",
      "env.sum_rewards:  -20.262999999977293\n",
      "len(self.memory) 47232\n",
      "recent training loss :  72.16048654812914\n",
      "env.sum_rewards:  -20.198999999977215\n",
      "len(self.memory) 47296\n",
      "recent training loss :  73.66548279221693\n",
      "env.sum_rewards:  -20.134999999977136\n",
      "len(self.memory) 47360\n",
      "recent training loss :  65.64329944549685\n",
      "env.sum_rewards:  -20.070999999977058\n",
      "len(self.memory) 47424\n",
      "recent training loss :  77.34800976009356\n",
      "env.sum_rewards:  -21.00799999997698\n",
      "len(self.memory) 47488\n",
      "recent training loss :  75.25136630604946\n",
      "env.sum_rewards:  -20.943999999976903\n",
      "len(self.memory) 47552\n",
      "recent training loss :  68.98275072954932\n",
      "env.sum_rewards:  -20.879999999976825\n",
      "len(self.memory) 47616\n",
      "recent training loss :  70.19298083668747\n",
      "env.sum_rewards:  -20.815999999976746\n",
      "len(self.memory) 47680\n",
      "recent training loss :  65.49539860858879\n",
      "env.sum_rewards:  -20.829999999976764\n",
      "len(self.memory) 47744\n",
      "recent training loss :  74.42029495671987\n",
      "env.sum_rewards:  -20.765999999976685\n",
      "len(self.memory) 47808\n",
      "recent training loss :  62.74508352694599\n",
      "env.sum_rewards:  -20.759999999976678\n",
      "len(self.memory) 47872\n",
      "recent training loss :  70.79875437204278\n",
      "env.sum_rewards:  -20.6959999999766\n",
      "len(self.memory) 47936\n",
      "recent training loss :  63.869418199495776\n",
      "env.sum_rewards:  -20.63199999997652\n",
      "len(self.memory) 48000\n",
      "recent training loss :  74.70154264853204\n",
      "env.sum_rewards:  -20.567999999976443\n",
      "len(self.memory) 48064\n",
      "recent training loss :  71.8418809153945\n",
      "env.sum_rewards:  -20.503999999976365\n",
      "len(self.memory) 48128\n",
      "recent training loss :  59.68266447362761\n",
      "env.sum_rewards:  -20.509999999976372\n",
      "len(self.memory) 48192\n",
      "recent training loss :  71.47861983228404\n",
      "env.sum_rewards:  -20.513999999976377\n",
      "len(self.memory) 48256\n",
      "recent training loss :  69.69938891939157\n",
      "env.sum_rewards:  -20.4499999999763\n",
      "len(self.memory) 48320\n",
      "recent training loss :  78.86387598036899\n",
      "env.sum_rewards:  -20.38599999997622\n",
      "len(self.memory) 48384\n",
      "recent training loss :  79.06159534606886\n",
      "env.sum_rewards:  -20.321999999976143\n",
      "len(self.memory) 48448\n",
      "recent training loss :  79.72558536519927\n",
      "env.sum_rewards:  -20.257999999976064\n",
      "len(self.memory) 48512\n",
      "recent training loss :  76.36316562802497\n",
      "env.sum_rewards:  -20.193999999975986\n",
      "len(self.memory) 48576\n",
      "recent training loss :  70.55536138592672\n",
      "env.sum_rewards:  -20.129999999975908\n",
      "len(self.memory) 48640\n",
      "recent training loss :  74.58688641014442\n",
      "env.sum_rewards:  -20.06599999997583\n",
      "len(self.memory) 48704\n",
      "recent training loss :  77.17278331881937\n",
      "env.sum_rewards:  -20.00199999997575\n",
      "len(self.memory) 48768\n",
      "recent training loss :  66.37389772046593\n",
      "env.sum_rewards:  -19.937999999975673\n",
      "len(self.memory) 48832\n",
      "recent training loss :  69.43742887409891\n",
      "env.sum_rewards:  -19.873999999975595\n",
      "len(self.memory) 48896\n",
      "recent training loss :  73.04108114963744\n",
      "env.sum_rewards:  -19.809999999975517\n",
      "len(self.memory) 48960\n",
      "recent training loss :  70.61231584794996\n",
      "env.sum_rewards:  -19.807999999975515\n",
      "len(self.memory) 49024\n",
      "recent training loss :  72.15965931552692\n",
      "env.sum_rewards:  -19.743999999975436\n",
      "len(self.memory) 49088\n",
      "recent training loss :  71.32528098479368\n",
      "env.sum_rewards:  -19.679999999975358\n",
      "len(self.memory) 49152\n",
      "recent training loss :  69.05980164157262\n",
      "env.sum_rewards:  -19.67199999997535\n",
      "len(self.memory) 49216\n",
      "recent training loss :  75.39221807158484\n",
      "env.sum_rewards:  -19.60799999997527\n",
      "len(self.memory) 49280\n",
      "recent training loss :  74.15516760627006\n",
      "env.sum_rewards:  -19.543999999975192\n",
      "len(self.memory) 49344\n",
      "recent training loss :  76.19930919330828\n",
      "env.sum_rewards:  -19.479999999975114\n",
      "len(self.memory) 49408\n",
      "recent training loss :  72.34674800755823\n",
      "env.sum_rewards:  -19.415999999975035\n",
      "len(self.memory) 49472\n",
      "recent training loss :  75.42131417481117\n",
      "env.sum_rewards:  -19.351999999974957\n",
      "len(self.memory) 49536\n",
      "recent training loss :  63.19981400224179\n",
      "env.sum_rewards:  -19.28799999997488\n",
      "len(self.memory) 49600\n",
      "recent training loss :  72.86037048621006\n",
      "env.sum_rewards:  -19.2239999999748\n",
      "len(self.memory) 49664\n",
      "recent training loss :  69.06516308595326\n",
      "env.sum_rewards:  -19.159999999974723\n",
      "len(self.memory) 49728\n",
      "recent training loss :  72.15720036016116\n",
      "env.sum_rewards:  -19.167999999974732\n",
      "len(self.memory) 49792\n",
      "recent training loss :  71.1828659410287\n",
      "env.sum_rewards:  -19.103999999974654\n",
      "len(self.memory) 49856\n",
      "recent training loss :  69.53983710298967\n",
      "env.sum_rewards:  -19.039999999974576\n",
      "len(self.memory) 49920\n",
      "recent training loss :  77.53278017989804\n",
      "env.sum_rewards:  -19.031999999974566\n",
      "len(self.memory) 49984\n",
      "recent training loss :  72.91781311973861\n",
      "env.sum_rewards:  -18.967999999974488\n",
      "len(self.memory) 50048\n",
      "recent training loss :  60.82162454731554\n",
      "env.sum_rewards:  -18.96999999997449\n",
      "len(self.memory) 50112\n",
      "recent training loss :  60.671183261082625\n",
      "env.sum_rewards:  -18.905999999974412\n",
      "len(self.memory) 50176\n",
      "recent training loss :  62.081935938040175\n",
      "env.sum_rewards:  -18.841999999974334\n",
      "len(self.memory) 50240\n",
      "recent training loss :  71.14168925023193\n",
      "env.sum_rewards:  -18.777999999974256\n",
      "len(self.memory) 50304\n",
      "recent training loss :  63.06582838176684\n",
      "env.sum_rewards:  -18.713999999974178\n",
      "len(self.memory) 50368\n",
      "recent training loss :  70.29905984653159\n",
      "env.sum_rewards:  -18.6499999999741\n",
      "len(self.memory) 50432\n",
      "recent training loss :  73.855753448993\n",
      "env.sum_rewards:  -17.628999999974074\n",
      "len(self.memory) 50496\n",
      "recent training loss :  68.37493283986285\n",
      "env.sum_rewards:  -17.564999999973995\n",
      "len(self.memory) 50560\n",
      "recent training loss :  70.73634969617206\n",
      "env.sum_rewards:  -17.500999999973917\n",
      "len(self.memory) 50624\n",
      "recent training loss :  61.542155451094786\n",
      "env.sum_rewards:  -17.43699999997384\n",
      "len(self.memory) 50688\n",
      "recent training loss :  73.2578435226322\n",
      "env.sum_rewards:  -17.37299999997376\n",
      "len(self.memory) 50752\n",
      "recent training loss :  73.99224750421047\n",
      "env.sum_rewards:  -17.368999999973756\n",
      "len(self.memory) 50816\n",
      "recent training loss :  63.02372552526083\n",
      "env.sum_rewards:  -17.304999999973678\n",
      "len(self.memory) 50880\n",
      "recent training loss :  63.18522850373768\n",
      "env.sum_rewards:  -17.2409999999736\n",
      "len(self.memory) 50944\n",
      "recent training loss :  65.95547229411494\n",
      "env.sum_rewards:  -17.17699999997352\n",
      "len(self.memory) 51008\n",
      "recent training loss :  67.7447286340247\n",
      "env.sum_rewards:  -17.112999999973443\n",
      "len(self.memory) 51072\n",
      "recent training loss :  75.2733805940738\n",
      "env.sum_rewards:  -17.048999999973365\n",
      "len(self.memory) 51136\n",
      "recent training loss :  62.253726212351296\n",
      "env.sum_rewards:  -17.042999999973357\n",
      "len(self.memory) 51200\n",
      "recent training loss :  62.685832452884725\n",
      "env.sum_rewards:  -16.97899999997328\n",
      "len(self.memory) 51264\n",
      "recent training loss :  74.64570612950729\n",
      "env.sum_rewards:  -16.96299999997326\n",
      "len(self.memory) 51328\n",
      "recent training loss :  64.46756670371428\n",
      "env.sum_rewards:  -16.960999999973257\n",
      "len(self.memory) 51392\n",
      "recent training loss :  66.69015116652884\n",
      "env.sum_rewards:  -16.89699999997318\n",
      "len(self.memory) 51456\n",
      "recent training loss :  72.15634722904183\n",
      "env.sum_rewards:  -16.8329999999731\n",
      "len(self.memory) 51520\n",
      "recent training loss :  70.72503264314949\n",
      "env.sum_rewards:  -16.768999999973023\n",
      "len(self.memory) 51584\n",
      "recent training loss :  69.84843985274512\n",
      "env.sum_rewards:  -16.76699999997302\n",
      "len(self.memory) 51648\n",
      "recent training loss :  73.70314787470986\n",
      "env.sum_rewards:  -16.702999999972942\n",
      "len(self.memory) 51712\n",
      "recent training loss :  62.961986160057634\n",
      "env.sum_rewards:  -17.639999999972865\n",
      "len(self.memory) 51776\n",
      "recent training loss :  59.98767281729285\n",
      "env.sum_rewards:  -17.575999999972787\n",
      "len(self.memory) 51840\n",
      "recent training loss :  72.77076936726937\n",
      "env.sum_rewards:  -17.51199999997271\n",
      "len(self.memory) 51904\n",
      "recent training loss :  71.38796622878698\n",
      "env.sum_rewards:  -17.44799999997263\n",
      "len(self.memory) 51968\n",
      "recent training loss :  65.93581695863928\n",
      "env.sum_rewards:  -17.441999999972623\n",
      "len(self.memory) 52032\n",
      "recent training loss :  70.62468504707542\n",
      "env.sum_rewards:  -17.377999999972545\n",
      "len(self.memory) 52096\n",
      "recent training loss :  62.7825528721779\n",
      "env.sum_rewards:  -17.38199999997255\n",
      "len(self.memory) 52160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recent training loss :  76.7245979077424\n",
      "env.sum_rewards:  -17.385999999972555\n",
      "len(self.memory) 52224\n",
      "recent training loss :  70.61287623743348\n",
      "env.sum_rewards:  -17.391999999972562\n",
      "len(self.memory) 52288\n",
      "recent training loss :  73.4988026885342\n",
      "env.sum_rewards:  -18.328999999972485\n",
      "len(self.memory) 52352\n",
      "recent training loss :  66.94834351358995\n",
      "env.sum_rewards:  -18.264999999972407\n",
      "len(self.memory) 52416\n",
      "recent training loss :  73.69770603167484\n",
      "env.sum_rewards:  -18.20099999997233\n",
      "len(self.memory) 52480\n",
      "recent training loss :  63.5176245466961\n",
      "env.sum_rewards:  -18.13699999997225\n",
      "len(self.memory) 52544\n",
      "recent training loss :  73.70309993824395\n",
      "env.sum_rewards:  -18.122999999972233\n",
      "len(self.memory) 52608\n",
      "recent training loss :  64.32272401436313\n",
      "env.sum_rewards:  -18.058999999972155\n",
      "len(self.memory) 52672\n",
      "recent training loss :  72.16126816308287\n",
      "env.sum_rewards:  -17.994999999972077\n",
      "len(self.memory) 52736\n",
      "recent training loss :  64.2293417855688\n",
      "env.sum_rewards:  -17.930999999972\n",
      "len(self.memory) 52800\n",
      "recent training loss :  72.2332396821617\n",
      "env.sum_rewards:  -17.86699999997192\n",
      "len(self.memory) 52864\n",
      "recent training loss :  65.49640491508728\n",
      "env.sum_rewards:  -17.844999999971893\n",
      "len(self.memory) 52928\n",
      "recent training loss :  67.58937807299428\n",
      "env.sum_rewards:  -17.83499999997188\n",
      "len(self.memory) 52992\n",
      "recent training loss :  62.97257641526146\n",
      "env.sum_rewards:  -17.770999999971803\n",
      "len(self.memory) 53056\n",
      "recent training loss :  65.3004964791362\n",
      "env.sum_rewards:  -17.706999999971725\n",
      "len(self.memory) 53120\n",
      "recent training loss :  70.61140066464488\n",
      "env.sum_rewards:  -17.642999999971646\n",
      "len(self.memory) 53184\n",
      "recent training loss :  70.70026624338983\n",
      "env.sum_rewards:  -17.63899999997164\n",
      "len(self.memory) 53248\n",
      "recent training loss :  62.875648981354644\n",
      "env.sum_rewards:  -17.63699999997164\n",
      "len(self.memory) 53312\n",
      "recent training loss :  65.96152910612793\n",
      "env.sum_rewards:  -17.57299999997156\n",
      "len(self.memory) 53376\n",
      "recent training loss :  71.41963209410822\n",
      "env.sum_rewards:  -17.508999999971483\n",
      "len(self.memory) 53440\n",
      "recent training loss :  67.51604177999698\n",
      "env.sum_rewards:  -17.444999999971404\n",
      "len(self.memory) 53504\n",
      "recent training loss :  69.06269341881367\n",
      "env.sum_rewards:  -17.380999999971326\n",
      "len(self.memory) 53568\n",
      "recent training loss :  61.455621794964095\n",
      "env.sum_rewards:  -17.316999999971248\n",
      "len(self.memory) 53632\n",
      "recent training loss :  62.95509635709354\n",
      "env.sum_rewards:  -17.25299999997117\n",
      "len(self.memory) 53696\n",
      "recent training loss :  80.37276657123385\n",
      "env.sum_rewards:  -17.18899999997109\n",
      "len(self.memory) 53760\n",
      "recent training loss :  62.875211064713255\n",
      "env.sum_rewards:  -17.198999999971104\n",
      "len(self.memory) 53824\n",
      "recent training loss :  75.24584484839465\n",
      "env.sum_rewards:  -17.134999999971026\n",
      "len(self.memory) 53888\n",
      "recent training loss :  73.96989349608836\n",
      "env.sum_rewards:  -17.070999999970947\n",
      "len(self.memory) 53952\n",
      "recent training loss :  76.3372995002432\n",
      "env.sum_rewards:  -17.00699999997087\n",
      "len(self.memory) 54016\n",
      "recent training loss :  61.57310244484104\n",
      "env.sum_rewards:  -16.94299999997079\n",
      "len(self.memory) 54080\n",
      "recent training loss :  62.85162181373894\n",
      "env.sum_rewards:  -16.878999999970713\n",
      "len(self.memory) 54144\n",
      "recent training loss :  70.82952542513767\n",
      "env.sum_rewards:  -16.814999999970635\n",
      "len(self.memory) 54208\n",
      "recent training loss :  75.42903949612824\n",
      "env.sum_rewards:  -16.750999999970556\n",
      "len(self.memory) 54272\n",
      "recent training loss :  62.89345871310795\n",
      "env.sum_rewards:  -16.686999999970478\n",
      "len(self.memory) 54336\n",
      "recent training loss :  56.824407671611105\n",
      "env.sum_rewards:  -16.6229999999704\n",
      "len(self.memory) 54400\n",
      "recent training loss :  69.06242121389863\n",
      "env.sum_rewards:  -16.55899999997032\n",
      "len(self.memory) 54464\n",
      "recent training loss :  79.99434658850245\n",
      "env.sum_rewards:  -16.494999999970243\n",
      "len(self.memory) 54528\n",
      "recent training loss :  61.3299149845826\n",
      "env.sum_rewards:  -16.430999999970165\n",
      "len(self.memory) 54592\n",
      "recent training loss :  59.781036067460896\n",
      "env.sum_rewards:  -16.366999999970087\n",
      "len(self.memory) 54656\n",
      "recent training loss :  55.14056084201359\n",
      "env.sum_rewards:  -16.30299999997001\n",
      "len(self.memory) 54720\n",
      "recent training loss :  64.422795900172\n",
      "env.sum_rewards:  -16.30299999997001\n",
      "len(self.memory) 54784\n",
      "recent training loss :  66.03069210092795\n",
      "env.sum_rewards:  -16.23899999996993\n",
      "len(self.memory) 54848\n",
      "recent training loss :  66.96612654651136\n",
      "env.sum_rewards:  -16.174999999969852\n",
      "len(self.memory) 54912\n",
      "recent training loss :  64.422104282585\n",
      "env.sum_rewards:  -16.110999999969774\n",
      "len(self.memory) 54976\n",
      "recent training loss :  73.7013296358034\n",
      "env.sum_rewards:  -16.046999999969696\n",
      "len(self.memory) 55040\n",
      "recent training loss :  67.6729855397069\n",
      "env.sum_rewards:  -15.98299999996965\n",
      "len(self.memory) 55104\n",
      "recent training loss :  56.74462444482117\n",
      "env.sum_rewards:  -15.918999999969685\n",
      "len(self.memory) 55168\n",
      "recent training loss :  58.26428253887802\n",
      "env.sum_rewards:  -15.912999999969689\n",
      "len(self.memory) 55232\n",
      "recent training loss :  59.83051990050063\n",
      "env.sum_rewards:  -15.848999999969724\n",
      "len(self.memory) 55296\n",
      "recent training loss :  68.498257114649\n",
      "env.sum_rewards:  -15.78499999996976\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3840\\3495834689.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;31m#             print('action taken : ', action)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m             \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;31m#             print('Next state dtype ; ', next_state.dtype)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;31m#             print('Next state ', next_state)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\gym\\wrappers\\order_enforcing.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_reset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mResetNeeded\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot call env.step() before calling env.reset()\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\gym\\wrappers\\env_checker.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mpassive_env_step_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mObsType\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mObsType\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Projects\\idt-innovation\\gym-fraud\\gym_fraud\\envs\\fraud_env.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, predicted_action_index)\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredicted_action\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_action_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_reward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_action_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_next_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mturns\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum_rewards\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepisode_over\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Projects\\idt-innovation\\gym-fraud\\gym_fraud\\envs\\fraud_env.py\u001b[0m in \u001b[0;36m_get_next_state\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf_xy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0mnew_state_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_state_index\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mnext_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_state_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_state_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_state_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    929\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 931\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1565\u001b[0m             \u001b[1;31m# validate the location\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1566\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1568\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1498\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1499\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1500\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1502\u001b[0m     \u001b[1;31m# -------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "# check reward strategy once\n",
    "# add probability to epsilon_greedy\n",
    "import json\n",
    "deep_agent = Agent(action_size=2, seed=0)\n",
    "num_episodes = 2\n",
    "max_t = 500\n",
    "state = 0\n",
    "env.state_idx = 0\n",
    "\n",
    "true_positive = []\n",
    "true_negative = []\n",
    "\n",
    "false_positive = []\n",
    "false_negative = []\n",
    "\n",
    "TPR = []\n",
    "FPR = []\n",
    "\n",
    "current_state = df.iloc[0, :-1].values\n",
    "\n",
    "for i in range(num_episodes):  \n",
    "  print(\"==========================EPOCH {} COMPLETED===================\".format(i))  \n",
    "\n",
    "  print('Current state : ', i)\n",
    "  score = 0\n",
    "  for state_idx, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "#         print(inputs)\n",
    "#         print(data)\n",
    "        print(\"env.sum_rewards: \", env.sum_rewards)\n",
    "        action = deep_agent.epsilon_greedy_action(inputs)\n",
    "        for a in action:\n",
    "#             print('action taken : ', action)\n",
    "            next_state, reward, done, info = env.step(a)\n",
    "#             print('Next state dtype ; ', next_state.dtype)\n",
    "#             print('Next state ', next_state)\n",
    "            deep_agent.step(current_state, a, reward, next_state, done)\n",
    "            current_state = next_state\n",
    "        if state_idx > max_t:\n",
    "            print(\"max_t exceeded: \", state_idx)\n",
    "            break\n",
    "#             state = next_state\n",
    "#             score += reward\n",
    "#             print(type(info), env.step(a))\n",
    "#             roc_info = json.loads(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "869G7Tttyvfi",
    "outputId": "f6310620-1134-4fb1-fce7-8cfa8ee2faed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'training loss')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plt.plot(x, y1, \"-b\", label=\"sine\")\n",
    "\n",
    "\n",
    "plt.plot(range((max_t+2)*num_episodes), deep_agent.train_loss, color='orange', label='Training Loss')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel('#epochs')\n",
    "plt.ylabel('training loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OPE-i1epzMHa"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected np.ndarray (got Tensor)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20524\\3740527721.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected np.ndarray (got Tensor)"
     ]
    }
   ],
   "source": [
    "X_test = torch.from_numpy(X_test)\n",
    "Y_test = torch.from_numpy(Y_test).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PZblBkJlzUs7"
   },
   "outputs": [],
   "source": [
    "test = data_utils.TensorDataset(X_test, Y_test)\n",
    "test_loader = data_utils.DataLoader(test, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "X_gkEla-zXAK",
    "outputId": "f1f37533-5e38-467d-e6fd-a8d49904222e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "100.0\n",
      "torch.int64\n",
      "99.21875\n",
      "torch.int64\n",
      "98.95833333333333\n",
      "torch.int64\n",
      "99.21875\n",
      "torch.int64\n",
      "99.0625\n",
      "torch.int64\n",
      "98.69791666666667\n",
      "torch.int64\n",
      "98.66071428571429\n",
      "torch.int64\n",
      "98.046875\n",
      "torch.int64\n",
      "97.91666666666667\n",
      "torch.int64\n",
      "98.125\n",
      "torch.int64\n",
      "98.01136363636364\n",
      "torch.float64\n",
      "94.53125\n",
      "torch.int64\n",
      "94.83173076923077\n",
      "torch.int64\n",
      "95.20089285714286\n",
      "torch.int64\n",
      "95.52083333333333\n",
      "torch.int64\n",
      "95.703125\n",
      "torch.int64\n",
      "95.86397058823529\n",
      "torch.float64\n",
      "93.05555555555556\n",
      "torch.int64\n",
      "93.25657894736842\n",
      "torch.int64\n",
      "93.515625\n",
      "torch.float64\n",
      "91.44345238095238\n",
      "torch.float64\n",
      "89.98579545454545\n",
      "torch.int64\n",
      "90.4211956521739\n",
      "torch.int64\n",
      "90.625\n",
      "torch.int64\n",
      "91.0\n",
      "torch.int64\n",
      "91.34615384615384\n",
      "torch.int64\n",
      "91.66666666666667\n",
      "torch.int64\n",
      "91.85267857142857\n",
      "torch.int64\n",
      "92.02586206896552\n",
      "torch.int64\n",
      "92.23958333333333\n",
      "torch.int64\n",
      "92.43951612903226\n",
      "torch.float64\n",
      "91.064453125\n",
      "torch.int64\n",
      "91.28787878787878\n",
      "torch.int64\n",
      "91.49816176470588\n",
      "torch.int64\n",
      "91.65178571428571\n",
      "torch.int64\n",
      "91.84027777777777\n",
      "torch.int64\n",
      "92.0608108108108\n",
      "torch.int64\n",
      "92.1875\n",
      "torch.int64\n",
      "92.38782051282051\n",
      "torch.float64\n",
      "91.2890625\n",
      "torch.int64\n",
      "91.5015243902439\n",
      "torch.int64\n",
      "91.66666666666667\n",
      "torch.int64\n",
      "91.75145348837209\n",
      "torch.float64\n",
      "90.76704545454545\n",
      "torch.float64\n",
      "89.89583333333333\n",
      "torch.int64\n",
      "90.01358695652173\n",
      "torch.int64\n",
      "90.22606382978724\n",
      "torch.int64\n",
      "90.4296875\n",
      "torch.float64\n",
      "89.54081632653062\n",
      "torch.int64\n",
      "89.6875\n",
      "torch.int64\n",
      "89.85906862745098\n",
      "torch.float64\n",
      "89.0625\n",
      "torch.int64\n",
      "89.23938679245283\n",
      "torch.int64\n",
      "89.4386574074074\n",
      "torch.int64\n",
      "89.60227272727273\n",
      "torch.int64\n",
      "89.76004464285714\n",
      "torch.int64\n",
      "89.93969298245614\n",
      "torch.int64\n",
      "90.05926724137932\n",
      "torch.int64\n",
      "90.22775423728814\n",
      "torch.float64\n",
      "89.58333333333333\n",
      "torch.int64\n",
      "89.75409836065573\n",
      "torch.int64\n",
      "89.91935483870968\n",
      "torch.int64\n",
      "90.07936507936508\n",
      "torch.float64\n",
      "89.6484375\n",
      "torch.int64\n",
      "89.8076923076923\n",
      "torch.int64\n",
      "89.96212121212122\n",
      "torch.int64\n",
      "90.11194029850746\n",
      "torch.int64\n",
      "90.25735294117646\n",
      "torch.int64\n",
      "90.39855072463769\n",
      "torch.int64\n",
      "90.53571428571429\n",
      "torch.int64\n",
      "90.66901408450704\n",
      "torch.int64\n",
      "90.77690972222223\n",
      "torch.int64\n",
      "90.90325342465754\n",
      "torch.int64\n",
      "91.02618243243244\n",
      "torch.int64\n",
      "91.125\n",
      "torch.int64\n",
      "91.24177631578948\n",
      "torch.int64\n",
      "91.33522727272727\n",
      "torch.int64\n",
      "91.42628205128206\n",
      "torch.float64\n",
      "90.8623417721519\n",
      "torch.int64\n",
      "90.9765625\n",
      "torch.int64\n",
      "91.06867283950618\n",
      "torch.int64\n",
      "91.17759146341463\n",
      "torch.int64\n",
      "91.26506024096386\n",
      "torch.int64\n",
      "91.33184523809524\n",
      "torch.float64\n",
      "90.7904411764706\n",
      "torch.int64\n",
      "90.87936046511628\n",
      "torch.int64\n",
      "90.94827586206897\n",
      "torch.int64\n",
      "91.05113636363636\n",
      "torch.int64\n",
      "91.09901685393258\n",
      "torch.float64\n",
      "90.60763888888889\n",
      "torch.int64\n",
      "90.67651098901099\n",
      "torch.int64\n",
      "90.74388586956522\n",
      "torch.int64\n",
      "90.80981182795699\n",
      "torch.int64\n",
      "90.87433510638297\n",
      "torch.int64\n",
      "90.95394736842105\n",
      "torch.int64\n",
      "91.04817708333333\n",
      "torch.int64\n",
      "91.1082474226804\n",
      "torch.float64\n",
      "90.51339285714286\n",
      "torch.int64\n",
      "90.59343434343434\n",
      "torch.float64\n",
      "90.203125\n",
      "torch.int64\n",
      "90.28465346534654\n",
      "torch.int64\n",
      "90.37990196078431\n",
      "torch.float64\n",
      "89.97269417475728\n",
      "torch.int64\n",
      "90.02403846153847\n",
      "torch.float64\n",
      "89.64285714285714\n",
      "torch.int64\n",
      "89.69634433962264\n",
      "torch.int64\n",
      "89.76343457943925\n",
      "torch.float64\n",
      "89.27951388888889\n",
      "torch.int64\n",
      "89.37786697247707\n",
      "torch.int64\n",
      "89.46022727272727\n",
      "torch.float64\n",
      "89.02027027027027\n",
      "torch.int64\n",
      "89.07645089285714\n",
      "torch.int64\n",
      "89.14546460176992\n",
      "torch.int64\n",
      "89.22697368421052\n",
      "torch.int64\n",
      "89.29347826086956\n",
      "torch.int64\n",
      "89.37230603448276\n",
      "torch.int64\n",
      "89.42307692307692\n",
      "torch.float64\n",
      "89.10222457627118\n",
      "torch.int64\n",
      "89.16754201680672\n",
      "torch.int64\n",
      "89.2578125\n",
      "torch.int64\n",
      "89.30785123966942\n",
      "torch.int64\n",
      "89.3826844262295\n",
      "torch.int64\n",
      "89.45630081300813\n",
      "torch.int64\n",
      "89.5413306451613\n",
      "torch.int64\n",
      "89.6125\n",
      "torch.float64\n",
      "89.32291666666667\n",
      "torch.int64\n",
      "89.39468503937007\n",
      "torch.int64\n",
      "89.4775390625\n",
      "torch.float64\n",
      "89.23207364341086\n",
      "torch.float64\n",
      "88.90625\n",
      "torch.int64\n",
      "88.97900763358778\n",
      "torch.int64\n",
      "89.0625\n",
      "torch.int64\n",
      "89.13298872180451\n",
      "torch.int64\n",
      "89.20242537313433\n",
      "torch.int64\n",
      "89.27083333333333\n",
      "torch.int64\n",
      "89.3267463235294\n",
      "torch.float64\n",
      "89.08531021897811\n",
      "torch.int64\n",
      "89.16440217391305\n",
      "torch.int64\n",
      "89.23111510791367\n",
      "torch.int64\n",
      "89.26339285714286\n",
      "torch.int64\n",
      "89.32845744680851\n",
      "torch.int64\n",
      "89.38160211267606\n",
      "torch.int64\n",
      "89.4340034965035\n",
      "torch.int64\n",
      "89.50737847222223\n",
      "torch.int64\n",
      "89.56896551724138\n",
      "torch.int64\n",
      "89.64041095890411\n",
      "torch.float64\n",
      "89.3813775510204\n",
      "torch.int64\n",
      "89.42145270270271\n",
      "torch.float64\n",
      "89.14639261744966\n",
      "torch.int64\n",
      "89.19791666666667\n",
      "torch.float64\n",
      "89.02110927152317\n",
      "torch.int64\n",
      "89.09333881578948\n",
      "torch.int64\n",
      "89.16462418300654\n",
      "torch.int64\n",
      "89.20454545454545\n",
      "torch.int64\n",
      "89.26411290322581\n",
      "torch.int64\n",
      "89.29286858974359\n",
      "torch.int64\n",
      "89.35111464968153\n",
      "torch.int64\n",
      "89.41851265822785\n",
      "torch.float64\n",
      "89.15094339622641\n",
      "torch.int64\n",
      "89.21875\n",
      "torch.int64\n",
      "89.28571428571429\n",
      "torch.int64\n",
      "89.33256172839506\n",
      "torch.float64\n",
      "89.12001533742331\n",
      "torch.float64\n",
      "88.90053353658537\n",
      "torch.int64\n",
      "88.96780303030303\n",
      "torch.int64\n",
      "89.03426204819277\n",
      "torch.int64\n",
      "89.0999251497006\n",
      "torch.float64\n",
      "88.84858630952381\n",
      "torch.int64\n",
      "88.91457100591715\n",
      "torch.int64\n",
      "88.97058823529412\n",
      "torch.int64\n",
      "89.01681286549707\n",
      "torch.int64\n",
      "89.07158430232558\n",
      "torch.int64\n",
      "89.13475433526011\n",
      "torch.int64\n",
      "89.19719827586206\n",
      "torch.int64\n",
      "89.25892857142857\n",
      "torch.int64\n",
      "89.31107954545455\n",
      "torch.int64\n",
      "89.35381355932203\n",
      "torch.int64\n",
      "89.39606741573034\n",
      "torch.int64\n",
      "89.45530726256983\n",
      "torch.int64\n",
      "89.51388888888889\n",
      "torch.float64\n",
      "89.3128453038674\n",
      "torch.int64\n",
      "89.37156593406593\n",
      "torch.float64\n",
      "89.16495901639344\n",
      "torch.int64\n",
      "89.1898777173913\n",
      "torch.int64\n",
      "89.23986486486487\n",
      "torch.int64\n",
      "89.29771505376344\n",
      "torch.int64\n",
      "89.35494652406418\n",
      "torch.int64\n",
      "89.41156914893617\n",
      "torch.float64\n",
      "89.18650793650794\n",
      "torch.int64\n",
      "89.22697368421052\n",
      "torch.int64\n",
      "89.27519633507853\n",
      "torch.int64\n",
      "89.32291666666667\n",
      "torch.int64\n",
      "89.33775906735751\n",
      "torch.int64\n",
      "89.37661082474227\n",
      "torch.int64\n",
      "89.42307692307692\n",
      "torch.int64\n",
      "89.46109693877551\n",
      "torch.int64\n",
      "89.50666243654823\n",
      "torch.float64\n",
      "89.29924242424242\n",
      "torch.int64\n",
      "89.32945979899498\n",
      "torch.int64\n",
      "89.3828125\n",
      "torch.float64\n",
      "89.22574626865672\n",
      "torch.int64\n",
      "89.27908415841584\n",
      "torch.int64\n",
      "89.31650246305419\n",
      "torch.int64\n",
      "89.34589460784314\n",
      "torch.float64\n",
      "89.13871951219512\n",
      "torch.int64\n",
      "89.18385922330097\n",
      "torch.int64\n",
      "89.23611111111111\n",
      "torch.int64\n",
      "89.28786057692308\n",
      "torch.int64\n",
      "89.33911483253588\n",
      "torch.int64\n",
      "89.38244047619048\n",
      "torch.int64\n",
      "89.41795023696683\n",
      "torch.int64\n",
      "89.46786556603773\n",
      "torch.int64\n",
      "89.5099765258216\n",
      "torch.int64\n",
      "89.55169392523365\n",
      "torch.int64\n",
      "89.58575581395348\n",
      "torch.float64\n",
      "89.43142361111111\n",
      "torch.float64\n",
      "89.26411290322581\n",
      "torch.int64\n",
      "89.2990252293578\n",
      "torch.int64\n",
      "89.34788812785388\n",
      "torch.int64\n",
      "89.38210227272727\n",
      "torch.int64\n",
      "89.42307692307692\n",
      "torch.int64\n",
      "89.47072072072072\n",
      "torch.float64\n",
      "89.30072869955157\n",
      "torch.int64\n",
      "89.32756696428571\n",
      "torch.int64\n",
      "89.36805555555556\n",
      "torch.float64\n",
      "89.18003318584071\n",
      "torch.int64\n",
      "89.22081497797357\n",
      "torch.int64\n",
      "89.26809210526316\n",
      "torch.int64\n",
      "89.31495633187772\n",
      "torch.int64\n",
      "89.35461956521739\n",
      "torch.int64\n",
      "89.40070346320347\n",
      "torch.int64\n",
      "89.43292025862068\n",
      "torch.int64\n",
      "89.47156652360515\n",
      "torch.int64\n",
      "89.49652777777777\n",
      "torch.int64\n",
      "89.54122340425532\n",
      "torch.int64\n",
      "89.58554025423729\n",
      "torch.float64\n",
      "89.39873417721519\n",
      "torch.int64\n",
      "89.4235819327731\n",
      "torch.int64\n",
      "89.4612970711297\n",
      "torch.int64\n",
      "89.4921875\n",
      "torch.int64\n",
      "89.52930497925311\n",
      "torch.float64\n",
      "89.37887396694215\n",
      "torch.int64\n",
      "89.42258230452676\n",
      "torch.int64\n",
      "89.453125\n",
      "torch.int64\n",
      "89.48979591836735\n",
      "torch.float64\n",
      "89.31021341463415\n",
      "torch.int64\n",
      "89.35349190283401\n",
      "torch.float64\n",
      "89.18850806451613\n",
      "torch.int64\n",
      "89.22565261044177\n",
      "torch.int64\n",
      "89.2625\n",
      "torch.float64\n",
      "89.08740039840637\n",
      "torch.float64\n",
      "88.91369047619048\n",
      "torch.int64\n",
      "88.9451581027668\n",
      "torch.int64\n",
      "88.98252952755905\n",
      "torch.float64\n",
      "88.81127450980392\n",
      "torch.int64\n",
      "88.848876953125\n",
      "torch.int64\n",
      "88.88618677042801\n",
      "torch.int64\n",
      "88.9171511627907\n",
      "torch.int64\n",
      "88.95994208494209\n",
      "torch.int64\n",
      "88.984375\n",
      "torch.int64\n",
      "89.00862068965517\n",
      "torch.int64\n",
      "89.05057251908397\n",
      "torch.float64\n",
      "88.91397338403041\n",
      "torch.float64\n",
      "88.78432765151516\n",
      "torch.int64\n",
      "88.81485849056604\n",
      "torch.int64\n",
      "88.83928571428571\n",
      "torch.int64\n",
      "88.86938202247191\n",
      "torch.int64\n",
      "88.91091417910448\n",
      "torch.int64\n",
      "88.9521375464684\n",
      "torch.float64\n",
      "88.80787037037037\n",
      "torch.int64\n",
      "88.8434040590406\n",
      "torch.int64\n",
      "88.88442095588235\n",
      "torch.int64\n",
      "88.91941391941391\n",
      "torch.float64\n",
      "88.7944799270073\n",
      "torch.float64\n",
      "88.68181818181819\n",
      "torch.int64\n",
      "88.71716485507247\n",
      "torch.int64\n",
      "88.75225631768953\n",
      "torch.int64\n",
      "88.78709532374101\n",
      "torch.int64\n",
      "88.82728494623656\n",
      "torch.int64\n",
      "88.8671875\n",
      "torch.int64\n",
      "88.90124555160142\n",
      "torch.int64\n",
      "88.91843971631205\n",
      "torch.int64\n",
      "88.94103356890459\n",
      "torch.int64\n",
      "88.9799735915493\n",
      "torch.int64\n",
      "89.01864035087719\n",
      "torch.int64\n",
      "89.04064685314685\n",
      "torch.int64\n",
      "89.0625\n",
      "torch.int64\n",
      "89.10047743055556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n",
      "88.94896193771626\n",
      "torch.int64\n",
      "88.98706896551724\n",
      "torch.int64\n",
      "89.02491408934708\n",
      "torch.int64\n",
      "89.0625\n",
      "torch.int64\n",
      "89.09449658703072\n",
      "torch.int64\n",
      "89.13159013605443\n",
      "torch.int64\n",
      "89.16843220338983\n",
      "torch.int64\n",
      "89.20502533783784\n",
      "torch.int64\n",
      "89.23611111111111\n",
      "torch.int64\n",
      "89.26698825503355\n",
      "torch.int64\n",
      "89.29765886287625\n",
      "torch.int64\n",
      "89.3125\n",
      "torch.int64\n",
      "89.34281561461793\n",
      "torch.int64\n",
      "89.37810430463576\n",
      "torch.int64\n",
      "89.4131600660066\n",
      "torch.int64\n",
      "89.44798519736842\n",
      "torch.int64\n",
      "89.47233606557377\n",
      "torch.int64\n",
      "89.48120915032679\n",
      "torch.float64\n",
      "89.28644136807817\n",
      "torch.int64\n",
      "89.31107954545455\n",
      "torch.int64\n",
      "89.33050161812298\n",
      "torch.int64\n",
      "89.35987903225806\n",
      "torch.int64\n",
      "89.38906752411576\n",
      "torch.int64\n",
      "89.41806891025641\n",
      "torch.int64\n",
      "89.45187699680511\n",
      "torch.int64\n",
      "89.48049363057325\n",
      "torch.int64\n",
      "89.51388888888889\n",
      "torch.int64\n",
      "89.54707278481013\n",
      "torch.int64\n",
      "89.57018927444796\n",
      "torch.int64\n",
      "89.59316037735849\n",
      "torch.int64\n",
      "89.62578369905957\n",
      "torch.float64\n",
      "89.4921875\n",
      "torch.int64\n",
      "89.52492211838006\n",
      "torch.int64\n",
      "89.55260093167702\n",
      "torch.float64\n",
      "89.43014705882354\n",
      "torch.int64\n",
      "89.453125\n",
      "torch.float64\n",
      "89.3125\n",
      "torch.float64\n",
      "89.16794478527608\n",
      "torch.int64\n",
      "89.20107033639144\n",
      "torch.int64\n",
      "89.22923018292683\n",
      "torch.float64\n",
      "89.14323708206688\n",
      "torch.int64\n",
      "89.17140151515152\n",
      "torch.float64\n",
      "89.03889728096676\n",
      "torch.int64\n",
      "89.0672063253012\n",
      "torch.float64\n",
      "88.94988738738739\n",
      "torch.float64\n",
      "88.82391467065868\n",
      "torch.int64\n",
      "88.83861940298507\n",
      "torch.int64\n",
      "88.87183779761905\n",
      "torch.float64\n",
      "88.7704005934718\n",
      "torch.float64\n",
      "88.65569526627219\n",
      "torch.int64\n",
      "88.68455014749263\n",
      "torch.int64\n",
      "88.71323529411765\n",
      "torch.int64\n",
      "88.74175219941348\n",
      "torch.int64\n",
      "88.77010233918129\n",
      "torch.int64\n",
      "88.80284256559767\n",
      "torch.int64\n",
      "88.83085029069767\n",
      "torch.int64\n",
      "88.84963768115942\n",
      "torch.int64\n",
      "88.8818641618497\n",
      "torch.int64\n",
      "88.90039625360231\n",
      "torch.float64\n",
      "88.78861350574712\n",
      "torch.float64\n",
      "88.69985673352436\n",
      "torch.int64\n",
      "88.72767857142857\n",
      "torch.int64\n",
      "88.75534188034187\n",
      "torch.float64\n",
      "88.62748579545455\n",
      "torch.int64\n",
      "88.65527620396601\n",
      "torch.int64\n",
      "88.67849576271186\n",
      "torch.int64\n",
      "88.69718309859155\n",
      "torch.float64\n",
      "88.57092696629213\n",
      "torch.int64\n",
      "88.5985644257703\n",
      "torch.float64\n",
      "88.49074720670392\n",
      "torch.int64\n",
      "88.51845403899722\n",
      "torch.int64\n",
      "88.53298611111111\n",
      "torch.int64\n",
      "88.56042243767313\n",
      "torch.int64\n",
      "88.5833908839779\n",
      "torch.float64\n",
      "88.4641873278237\n",
      "torch.int64\n",
      "88.48729395604396\n",
      "torch.int64\n",
      "88.51883561643835\n",
      "torch.int64\n",
      "88.54593579234972\n",
      "torch.float64\n",
      "88.4409059945504\n",
      "torch.float64\n",
      "88.32370923913044\n",
      "torch.float64\n",
      "88.20291327913279\n",
      "torch.int64\n",
      "88.23057432432432\n",
      "torch.int64\n",
      "88.25387466307278\n",
      "torch.int64\n",
      "88.2770497311828\n",
      "torch.int64\n",
      "88.30428954423593\n",
      "torch.int64\n",
      "88.33138368983957\n",
      "torch.int64\n",
      "88.3625\n",
      "torch.int64\n",
      "88.38513962765957\n",
      "torch.int64\n",
      "88.40765915119363\n",
      "torch.int64\n",
      "88.43419312169313\n",
      "torch.int64\n",
      "88.45646437994723\n",
      "torch.int64\n",
      "88.48273026315789\n",
      "torch.int64\n",
      "88.50885826771653\n",
      "torch.int64\n",
      "88.53075916230367\n",
      "torch.int64\n",
      "88.552545691906\n",
      "torch.int64\n",
      "88.57828776041667\n",
      "torch.int64\n",
      "88.6038961038961\n",
      "torch.int64\n",
      "88.63341968911917\n",
      "torch.float64\n",
      "88.51744186046511\n",
      "torch.int64\n",
      "88.53092783505154\n",
      "torch.int64\n",
      "88.55237789203085\n",
      "torch.int64\n",
      "88.57371794871794\n",
      "torch.float64\n",
      "88.49504475703324\n",
      "torch.int64\n",
      "88.52439413265306\n",
      "torch.int64\n",
      "88.54961832061069\n",
      "torch.int64\n",
      "88.56678299492386\n",
      "torch.int64\n",
      "88.59572784810126\n",
      "torch.int64\n",
      "88.6205808080808\n",
      "torch.int64\n",
      "88.6374370277078\n",
      "torch.int64\n",
      "88.66598618090453\n",
      "torch.int64\n",
      "88.69439223057644\n",
      "torch.int64\n",
      "88.72265625\n",
      "torch.int64\n",
      "88.74688279301746\n",
      "torch.int64\n",
      "88.77487562189054\n",
      "torch.int64\n",
      "88.7988523573201\n",
      "torch.int64\n",
      "88.82657797029702\n",
      "torch.int64\n",
      "88.8503086419753\n",
      "torch.int64\n",
      "88.86622536945812\n",
      "torch.float64\n",
      "88.74769656019656\n",
      "torch.float64\n",
      "88.66038602941177\n",
      "torch.float64\n",
      "88.57350244498778\n",
      "torch.int64\n",
      "88.59375\n",
      "torch.int64\n",
      "88.61770072992701\n",
      "torch.float64\n",
      "88.53155339805825\n",
      "torch.float64\n",
      "88.43825665859565\n",
      "torch.float64\n",
      "88.32653985507247\n",
      "torch.int64\n",
      "88.3546686746988\n",
      "torch.int64\n",
      "88.37890625\n",
      "torch.int64\n",
      "88.40677458033574\n",
      "torch.int64\n",
      "88.43077153110048\n",
      "torch.int64\n",
      "88.45092482100239\n",
      "torch.int64\n",
      "88.47098214285714\n",
      "torch.int64\n",
      "88.49465558194774\n",
      "torch.float64\n",
      "88.38122037914692\n",
      "torch.int64\n",
      "88.40499408983452\n",
      "torch.int64\n",
      "88.42865566037736\n",
      "torch.int64\n",
      "88.45220588235294\n",
      "torch.int64\n",
      "88.4793133802817\n",
      "torch.int64\n",
      "88.50629391100702\n",
      "torch.float64\n",
      "88.43457943925233\n",
      "torch.int64\n",
      "88.45425407925408\n",
      "torch.int64\n",
      "88.4811046511628\n",
      "torch.int64\n",
      "88.4969547563805\n",
      "torch.int64\n",
      "88.52358217592592\n",
      "torch.int64\n",
      "88.54647806004618\n",
      "torch.float64\n",
      "88.46126152073732\n",
      "torch.float64\n",
      "88.36925287356321\n",
      "torch.int64\n",
      "88.3887614678899\n",
      "torch.int64\n",
      "88.40102974828375\n",
      "torch.int64\n",
      "88.42037671232876\n",
      "torch.int64\n",
      "88.43607630979498\n",
      "torch.int64\n",
      "88.45170454545455\n",
      "torch.int64\n",
      "88.47434807256236\n",
      "torch.int64\n",
      "88.49335407239819\n",
      "torch.int64\n",
      "88.50874717832957\n",
      "torch.int64\n",
      "88.53110923423424\n",
      "torch.int64\n",
      "88.55688202247191\n",
      "torch.int64\n",
      "88.55728380323724\n",
      "Accuracy of the network on the 28481 inputs: 88.55728380323724\n"
     ]
    }
   ],
   "source": [
    "tp = 0\n",
    "tn = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        predicted = deep_agent.epsilon_greedy_action(inputs)        \n",
    "        total += labels.size(0)\n",
    "        print(predicted.dtype)\n",
    "        correct += (predicted.double()==labels).sum().item() \n",
    "        print(100*correct/total)\n",
    "        for p, l in zip(predicted, labels):\n",
    "            if l == 1:\n",
    "                if p == 1:\n",
    "                    tp +=1\n",
    "                else:\n",
    "                    fn +=1\n",
    "            else:\n",
    "                if p == 0:\n",
    "                    tn +=1\n",
    "                else:\n",
    "                    fp +=1\n",
    "        \n",
    "\n",
    "print('Accuracy of the network on the {} inputs: {}'.format(\n",
    "    X_test.shape[0], 100 * correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SLZIhA38z3l-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 25193 3239 20\n"
     ]
    }
   ],
   "source": [
    "print(tp, tn, fp, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOi3jqHbtUjJ+mFtOb/KKq/",
   "include_colab_link": true,
   "name": "Credit_Card_Fraud_Detection_via_DQNs.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
